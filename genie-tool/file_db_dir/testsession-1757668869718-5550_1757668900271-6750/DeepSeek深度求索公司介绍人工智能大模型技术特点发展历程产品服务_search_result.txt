{"DeepSeek 与 SOTA模型 横向对比 性能指标 技术报告":[{"content":"本文将从技术演进**、核心架构、关键优化、工程实现四个维度，深度解析DeepSeek 如何突破传统Transformer 局限，构建高效、可扩展的大模型技术体系。我们将 ...","doc_type":"web_page","link":"https://blog.csdn.net/2301_77933942/article/details/150303710","title":"DeepSeek 架构详解：从Transformer 到MoE 模型原创"},{"content":"具体技术/成果. 训练成本. 硬件成本. - 采用MoE架构（混合专家模型），仅激活部分参数（如V3激活37B/671B参数）. - FP8混合精度训练减少内存占用与计算量.","doc_type":"web_page","link":"https://pdf.dfcfw.com/pdf/H3_AP202503051644069306_1.pdf","title":"DeepSeek 智能时代的全面到来和人机协作的新常态"},{"content":"为了进一步推动开源模型能力的发展，我们扩大了模型规模，并推出了DeepSeek-V3，这是一个拥有6710 亿参数的大型混合专家（MoE）模型，其中每个Token 激活370 亿个参数。我们以 ...","doc_type":"web_page","link":"https://zhuanlan.zhihu.com/p/15875767628","title":"DeepSeek-V3 技术报告全文详解"},{"content":"最新发布 DeepSeek 技术架构解析：从Transformer 到MoE 模型. DeepSeek是由中国深度求索公司开发的大规模语言模型系列，其核心创新在于Transformer架构 ...","doc_type":"web_page","link":"https://blog.csdn.net/fq1986614/article/details/145517821","title":"DeepSeek 混合专家（MoE）架构技术原理剖析"},{"content":"从技术角度看，DeepSeek采用了多项创新技术，比如混合专家（MoE）架构和多头潜在注意力（MLA）架构，大幅降低了计算成本，同时保持了高性能。其模型在数学、代码、 ...","doc_type":"web_page","link":"https://zhuanlan.zhihu.com/p/21968215201","title":"推上大佬都坐不住了！DeepSeek论文清单大公开"},{"content":"DeepSeek AI 通过高效计算架构解决了这些挑战，包括Dee. pSeek 混合专家框架（Mixture-of-Experts, MoE），该框架在. 保持性能的同时降低了推理成本。DeepSeek ...","doc_type":"web_page","link":"https://pdf.dfcfw.com/pdf/H3_AP202502141643086746_1.pdf?1739553070000.pdf","title":"DeepSeek 模型综述"},{"content":"他们将MoE定义为一种将多个“专家”网络组合起来的架构，每个专家网络负责处理输入数据的一个子集，而一个“门控网络”则负责分配输入到各个专家。这种架构的 ...","doc_type":"web_page","link":"https://cloud.tencent.com/developer/news/2205933","title":"DeepSeek中非常重要的混合专家模型MoE技术详解"},{"content":"在MoE 系统中，传统Transformer 模型中的每个前馈网络(FFN) 层替换为MoE 层，其中MoE 层由两个核心部分组成: 一个门控网络和若干数量的专家网络。 传统 ...","doc_type":"web_page","link":"http://www.360doc.com/content/25/0207/14/3066843_1146221243.shtml","title":"DeepSeek为什么采用与主流大模型不一样的MoE架构？ ..."},{"content":"... 大硬核创新重塑大模型架构范式。技术团队通过：1）首创多头潜注意力机制（MLA），攻克长文本推理的显存效率瓶颈；2）革新动态路由算法，突破MoE模型 ... DeepSeek ...","doc_type":"web_page","link":"https://www.51cto.com/aigc/3888.html","title":"DeepSeek 惊艳背后的技术架构创新剖析-AI.x-AIGC专属社区"},{"content":"国内首个MoE大模型（DeepSeek-MoE），各大模型在公开评测榜单及真实样本外的泛化效果均有超越同级别模型的出色表现。和DeepSeek AI 对话，轻松接入API。","doc_type":"web_page","link":"https://www.deepseek.com/","title":"DeepSeek | 深度求索"}],"DeepSeek 产品技术白皮书 架构细节 训练方法论 开源实现":[{"content":"经过数千轮RL迭代，DeepSeek-R1-Zero在推理基准测试中展现出优异性能。 例如，在AIME 2024测试中，pass@1得分从15.6%提升至71.0%，采用majority voting机制后，得分进一步提高 ...","doc_type":"web_page","link":"https://zhuanlan.zhihu.com/p/19744278380","title":"通过强化学习提升LLM的推理能力》——DeepSeek-R1技术 ..."},{"content":"实验结果：DeepSeek-R1在推理任务表现出色，AIME 2024上Pass@1得分79.8%超OpenAI-o1-1217，MATH-500上97.3%与OpenAI-o1-1217相当。在编码任务和知识基准测试 ...","doc_type":"web_page","link":"https://blog.csdn.net/YYDS_54/article/details/145489827","title":"【大模型】DeepSeek-R1 论文原文翻译+ 解读"},{"content":"DeepSeek系列大模型在数学、代码和自然语言推理等任务上表现非常出色，同时综合性能与OpenAI的o1正式版相当。并且发布即开源，向全球AI开发者开放，遵循MIT协议，支持完全免费 ...","doc_type":"web_page","link":"https://zhuanlan.zhihu.com/p/20739054077","title":"深入浅出完整解析DeepSeek系列核心基础知识"},{"content":"在SimpleQA基准测试中，DeepSeek-R1 超越了DeepSeek-V3，证明了其处理基于事实查询的能力。但是在中文SimpleQA 基准上，DeepSeek-R1 的表现不如DeepSeek-V3， ...","doc_type":"web_page","link":"https://swarma.org/?p=55394","title":"DeepSeek-R1｜集智百科"},{"content":"具体来说，团队在DeepSeek-R1的全模态化尝试中发现，多模态训练之后，模型不仅在文本模态任务上的表现有所提升，在科学任务、复杂推理、数学代码等方面的表现 ...","doc_type":"web_page","link":"https://www.qbitai.com/2025/02/250955.html","title":"多模态版DeepSeek-R1：评测表现超GPT-4o，模态穿透反哺 ..."},{"content":"• 利用DeepSeek-R1生成的推理数据，我们对研究社区中广泛使用的多个密集模型进行了微. 调。评估结果表明，经过蒸馏的较小密集模型在基准测试中表现尤为出色。DeepSeek-R1-.","doc_type":"web_page","link":"https://www.52nlp.cn/wp-content/uploads/2025/01/DeepSeek-R1-%E6%8A%80%E6%9C%AF%E6%8A%A5%E5%91%8A%E4%B8%AD%E6%96%87%E7%89%88-%E7%94%B1deepseek%E7%BF%BB%E8%AF%91.pdf","title":"DeepSeek-R1：通过强化学习激励LLMs中的推理能力"},{"content":"论文标题：DeepSeek-V3 Technical Report · 发布时间：2024 年12 月 · 主要内容：. DeepSeek-V3 是一款性能卓越的混合专家（MoE） 语言模型，整体参数规模达到671B ...","doc_type":"web_page","link":"https://blog.csdn.net/youcans/article/details/145515722","title":"【DeepSeek论文精读】5. DeepSeek-V3 技术报告原创"},{"content":"DeepSeek-R1-0528 仍然使用2024 年12 月所发布的DeepSeek V3 Base 模型作为基座，但在后训练过程中投入了更多算力，显著提升了模型的思维深度与推理能力。","doc_type":"web_page","link":"https://api-docs.deepseek.com/zh-cn/news/news250528","title":"DeepSeek-R1 更新，思考更深，推理更强"},{"content":"为了实现高效的推理和成本效益的训练，DeepSeek-V3采用了Multi-head Latent Attention (MLA) 和DeepSeekMoE 架构，这些架构在DeepSeek-V2中得到了彻底验证。","doc_type":"web_page","link":"http://www.360doc.com/content/25/0131/20/32196507_1145659124.shtml","title":"DeepSeek-V3技术报告解读-超详细"},{"content":"从测评结果可见，多款开源小参数量模型展现出惊人潜力。尤其是DeepSeek-R1-Distill系列，. 在数学推理任务中表现十分突出，其中7B和14B版本分别取得了77.23分 ...","doc_type":"web_page","link":"https://people.5cy.com/p4/jianzhi_baogao/jzsj-hybg-20250402-pdf_11.pdf","title":"中文大模型基准测评2025年3月报告"}],"DeepSeek 训练策略 超参数配置 分布式训练 最新研究":[{"content":"在保持性能不变的情况下，论文采用了双重视角——跨越硬件架构和模型设计，通过研究这种协同作用，探索DeepSeek-V3 如何实现经济高效的大规模训练和推理。 随着 ...","doc_type":"web_page","link":"https://zhuanlan.zhihu.com/p/1906400611987064499","title":"首次披露！DeepSeek V3 发布软硬一体协同训练论文"},{"content":"DeepSeek是一款高性能预训练语言模型，采用分布式训练架构和多种并行策略，如流水线并行、专家并行和数据并行，结合关键技术优化如DualPipe算法和跨节点 ...","doc_type":"web_page","link":"https://cloud.tencent.com/developer/article/2497241","title":"DeepSeek分布式模型训练详解"},{"content":"这篇14 页的论文瞄向了「Scaling 挑战以及对AI 架构所用硬件的思考」。从中你不仅能读到DeepSeek 在开发和训练V3 过程中发现的问题和积累的心得，还能 ...","doc_type":"web_page","link":"https://www.cnblogs.com/wujianming-110117/p/18880657","title":"DeepSeek-V3新论文，低成本训练大模型的秘密揭开"},{"content":"相比同等规模的模型（如GPT-4、GPT-40. Llama3.1），训练成本大幅降低。但DeepSeek团队还特意强调，上述成本仅包括DeepSeek-v3的官方训练，不包括与架构，. 算法 ...","doc_type":"web_page","link":"https://pdf.dfcfw.com/pdf/H3_AP202503071644137559_1.pdf?1741340780000.pdf","title":"Deepseek技术全景解析"},{"content":"SFT 训练配置： 研究对DeepSeek-V3-Base 进行了两轮SFT 数据集训练，采用余弦衰减的学习率调度策略，初始学习率为 5\\times10^{-6}，逐步降低至 1\\times10^{-6}。训练 ...","doc_type":"web_page","link":"https://zhuanlan.zhihu.com/p/14890557782","title":"【LLM技术报告】DeepSeek-V3技术报告（全文）"},{"content":"... 分布式训练网络，实现对全球算力资源的整合。DeepSeek的未来战略将聚焦于技术深耕、市场拓展和平台生态建设，实现从单一模型开发商向AI基础设施运营商 ...","doc_type":"web_page","link":"http://gjs.cssn.cn/kydt/kydt_kycg/202508/t20250806_5909532.shtml","title":"DeepSeek技术突围重构全球人工智能产业竞争格局的六个维度"},{"content":"1）优化训练超参数：通过合理调整训练超参数来降低成本。使用学习率退火策略，在训练初期设置较大的学习率以加快收敛速度，在训练后期逐渐减小学习率 ...","doc_type":"web_page","link":"https://www.9fzt.com/common/a94894dfbc884026e784f0ca6102067b.html","title":"再谈DeepSeek（深度求索）：有限计算资源下的顶尖大模型"},{"content":"3.2 关键超参数调优建议. 初始缩放因子：. 默认值256适用于大多数场景; 数值不稳定时建议调整为1024或4096. 动态调整周期： # 每500步调整一次缩放因子 ...","doc_type":"web_page","link":"https://blog.csdn.net/xiaoganbuaiuk/article/details/147783186","title":"DeepSeek分布式训练框架中的混合精度计算：硬件成本优化 ..."},{"content":"· 分布式训练协调:多节点通信(NCCL/MPI)依赖CPU调度,建议≥32核/节点。 · 显存 Offloading：若使用CPU内存卸载参数（ZeRO-Infinity），需≥64 核,以加速数据交换 ...","doc_type":"web_page","link":"https://al3crt20231227.xasun.com/article/110/2929.html","title":"满血版Deepseek R1本地部署服务器/工作站硬件配置精准分析 ..."},{"content":"超参数调优. 使用Optuna框架实现分布式超参数搜索; 实施贝叶斯优化算法,提高搜索效率; 开发超参数继承机制,利用历史训练结果加速调优. 性能评估与调优.","doc_type":"web_page","link":"https://www.shilubi.com/deepseek/20344.html","title":"DeepSeek的分布式训练性能如何提升？_狗鼻子AI工具导航网"}],"DeepSeek 评测基准 中英文跨域能力 推理任务表现 2024":[{"content":"尽管其训练成本较低，但综合评估结果显示，DeepSeek-V3-Base 已成为当前性能最强的开源基础模型，尤其在代码和数学领域表现卓越。其对话版本不仅超越了其他开源模型，还在多个 ...","doc_type":"web_page","link":"https://zhuanlan.zhihu.com/p/14890557782","title":"【LLM技术报告】DeepSeek-V3技术报告（全文）"},{"content":"DeepSeek秉持开源到底的决心，将R1模型的训练技术全部开放，放出背后的研究论文。 R1技术报告. 以往的研究，主要依赖大量监督数据来提升模型性能。 DeepSeek ...","doc_type":"web_page","link":"https://zhuanlan.zhihu.com/p/23142667669","title":"【智能前线】第22期：DeepSeek特辑，开源低成本模型开启AI ..."},{"content":"DeepSeek-R1 的效果示意：更少的GPU（或其他. AI 芯片）带来同样的效果高DeepSeek-R1 提供了一种低成. 本训练的方法，而不是说只能通过低成本来进行训练。","doc_type":"web_page","link":"https://pdf.dfcfw.com/pdf/H3_AP202503071644144703_1.pdf?1741388026000.pdf","title":"deepseek 大模型生态报告"},{"content":"其一，凭借技术优势，DeepSeek一举进入国际大模型头部梯队，这给国内大 ... SOTA水平，性能优于Qwen2.5-VL 72B，是目前最强的端侧多模态模型 ...","doc_type":"web_page","link":"https://hub.baai.ac.cn/view/43437","title":"中科院系黑马闯入全球TOP 10！破解高精度-低能耗困局"},{"content":"本文对市面上主流的DeepSeek 模型API 服务进行了全面的性能评测，包括火山引擎、OpenRouter 和DeepSeek 官方等渠道。通过对首字响应时间、生成速度、 ...","doc_type":"web_page","link":"https://ginonotes.com/posts/deepseek-provider-test","title":"DeepSeek 模型多渠道API 性能评测（20250217 版）"},{"content":"由深度求索公司研发的开源大模型DeepSeek以\"低成本+高智能+全开源\"的颠覆性优势横空出世，犹如一条激活全球AI生态的鲶鱼，在科技界掀起惊涛骇浪。","doc_type":"web_page","link":"https://m.bjnews.com.cn/detail/1739776076129423.html","title":"大模型震荡时刻：DeepSeek掀桌百度开源免费成必答题"},{"content":"在AI军备竞赛白热化的2024年，DeepSeek-V3以惊人的推理速度震撼业界：相比前代模型推理速度提升3倍，训练成本降低70%。这背后是十余项革命性技术的叠加创新， ...","doc_type":"web_page","link":"https://juejin.cn/post/7471206731273502735","title":"DeepSeek-V3为何成为大模型时代的\"速度之王\"？"},{"content":"深度分析各数据集的任务定义、规模、领域、评测指标及代表性模型性能，揭示任务演进规律与技术挑战； ... 指标，评估表格布局合理性，SOTA模型得分仅62.3%。","doc_type":"web_page","link":"https://cloud.tencent.com/developer/article/2539676","title":"信息抽取数据集全景分析：分类体系、技术演进与挑战"},{"content":"在AIME 2024测试中，平均pass@1得分从初始的15.6%显著提升至71.0%，达到OpenAI-o1-0912的性能水平，充分证实了RL算法在模型性能优化方面的有效性。 表2 | ...","doc_type":"web_page","link":"http://139.9.1.231/index.php/2025/02/06/deepseek-r1/","title":"DeepSeek-R1 技术报告"},{"content":"2024-12-26，DeepSeek-V3即将开源 · 2025-01-03，从infra的视角聊聊DeepSeek-V3 · 2025-01-05，DeepSeek-V3技术报告完整解读 · 2025-04-24，RL x LLM 时代：通向AGI 的四层 ...","doc_type":"web_page","link":"https://github.com/coderonion/awesome-llm-and-aigc","title":"Awesome-llm-and-aigc"}],"DeepSeek 大模型 Transformer 架构 MoE 设计 技术白皮书":[{"content":"为了实现高效的推理和具有成本效益的训练，DeepSeek-V3 采用了多头潜在注意力 (MLA) 和DeepSeekMoE 架构，这些架构在DeepSeek-V2 中得到了充分验证。此外，DeepSeek-V3 首创了 ...","doc_type":"web_page","link":"https://zhuanlan.zhihu.com/p/15875767628","title":"DeepSeek-V3 技术报告全文详解"},{"content":"基于算力网调度平台，本白皮书将重点阐述用户接入调度平台进行大 模型业务加速所需的功能架构，主要包括以下五个模块： （1）用户管理。","doc_type":"web_page","link":"https://www.gfnds.com/uploads/20250820/793b3255544ff1197ef8f7762911db1b.pdf","title":"DeepSeek行业大模型算力网加速应用生态技术白皮书"},{"content":"DeepSeek V3和R1模型基于Transformer架构，采用了MLA和DeepSeek MoE两大核心技术，引入了多令牌预测、FP8混合精度训练等创新技术，显著提升了模型的训练效率 ...","doc_type":"web_page","link":"https://www.eet-china.com/mp/a381959.html","title":"DeepSeek研究框架（2025）"},{"content":"内容概要：本文详细分析了DeepSeek-V3在高效训练方面采用的关键技术，包括模型架构、负载均衡策略、并行策略、通信优化和显存优化。","doc_type":"web_page","link":"https://blog.csdn.net/bylander/article/details/144792492","title":"【AI学习】DeepSeek-V3 技术报告学习：总体架构原创"},{"content":"为了实现高效推理和经济高效的训练，DeepSeek-V3 采用了多头潜在注意力（MLA）和DeepSeekMoE 架构，这些架构在DeepSeek-V2 中已得到充分验证。 此外，DeepSeek- ...","doc_type":"web_page","link":"https://blog.csdn.net/2401_85343303/article/details/145041630","title":"最强开源媲美闭源| 万字详解DeepSeek-V3 技术报告！ 原创"},{"content":"尽管R1 不是第一个开源推理模型，但它比之前的模型（如阿里巴巴的QwQ）更强大。与DeepSeek-V3 一样，它也采用了非常规的方法来实现其结果。 大多数LLMs 的训练 ...","doc_type":"web_page","link":"https://zhuanlan.zhihu.com/p/22459660268","title":"DeepSeek 对开源人工智能的意义"},{"content":"本文来自“DeepSeek使用教程蓝皮书：从入门到进阶完整指南”，在人工智能技术高速迭代的时代背景下，推理模型作为核心驱动力，持续重塑各行业的发展格局。","doc_type":"web_page","link":"https://www.eet-china.com/mp/a382718.html","title":"DeepSeek蓝皮书：从入门到进阶完整指南"},{"content":"DeepSeek 在开源中展现了诸多创新，例如混合质量模型Moe、多头潜在注意力机制MLA，以及强化学习中的GRPO 算法，这些都优于OpenAI 所使用的PPO 算法。此外， ...","doc_type":"web_page","link":"https://www.infoq.cn/article/orecrxrfyxz1bl5ssdsl","title":"DeepSeek绝不仅仅是开源的胜利_云计算"},{"content":"DeepSeek V3和R1模型基于Transformer架构，采用了MLA和DeepSeek MoE两大核心技术，引入了多令牌预测、FP8混合精度训练等创新技术，显著提升了模型的训练效率和推理性能。","doc_type":"web_page","link":"https://www.scribd.com/document/827975256/DeepSeek%E7%A0%94%E7%A9%B6%E6%A1%86%E6%9E%B620250204-%E5%9B%BD%E6%B5%B7%E8%AE%A1%E7%AE%97%E6%9C%BA","title":"DeepSeek研究框架20250204 国海计算机"},{"content":"... 训练方法的完全开源。 开源即将模型的源代码和技术细节公开，并允许用户根据其自身需要对模型进行任意使用和修改，这被认为有提高技术透明度，让用户更容易、更便宜地 ...","doc_type":"web_page","link":"https://www.yicai.com/news/102456896.html","title":"DeepSeek“刷屏”硅谷：芯片管制反激发中国大模型创新力？"}]}