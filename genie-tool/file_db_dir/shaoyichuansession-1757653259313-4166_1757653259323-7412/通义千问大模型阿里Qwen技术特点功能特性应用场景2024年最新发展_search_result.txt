{"Qwen 多模态扩展 长上下文处理 技术更新 2024":[{"content":"Qwen2.5-Turbo：使用采用了渐进式上下文长度扩展策略，在每个阶段，训练数据中包含当前最大长度的序列和较短的序列，以使模型逐步适应更长的上下文，经过多阶段 ...","doc_type":"web_page","link":"https://zhuanlan.zhihu.com/p/14441104741","title":"【论文解读】Qwen2.5 技术报告"},{"content":"通义千问是由阿里云自主研发的大模型，用于理解和分析用户输入的自然语言，以及图片、音频、视频等多模态数据。在不同领域和任务为用户提供服务和帮助。","doc_type":"web_page","link":"https://help.aliyun.com/zh/model-studio/what-is-qwen-llm","title":"通义千问大语言模型介绍 - 阿里云文档"},{"content":"（3）长上下文阶段（S3）：最终预训练阶段，研究人员收集了高质量长上下文语料库以扩展Qwen3模型的上下文处理长度。所有模型在数百亿token上进行预训练，序列长度达32K token。长 ...","doc_type":"web_page","link":"https://zhuanlan.zhihu.com/p/1905945819108079268","title":"【LLM技术报告】Qwen3技术报告（全文）"},{"content":"多语言支持： 为了服务全球用户，Qwen2-VL现在支持图像内的多语言上下文理解，包括大多数欧洲语言、日语、韩语、阿拉伯语、越南语等。 3 实验. 在本节中，作者 ...","doc_type":"web_page","link":"https://blog.csdn.net/my_name_is_learn/article/details/143451029","title":"发表于2024年10月Qwen2-VL 迅速崛起| 性能与GPT-4o和 ..."},{"content":"今天，我们隆重推出新的Qwen2.5-Turbo 版本，其特点在于：. 更长的上下文支持: 我们首次将模型的上下文长度从128k 扩展到1M，该长度约为100 万个英文单词 ...","doc_type":"web_page","link":"https://qwenlm.github.io/zh/blog/qwen2.5-turbo/","title":"将上下文长度扩展至百万Tokens ！ | Qwen"},{"content":"Naive动态分辨率. Qwen2-VL 的一项关键架构改进是引入了朴素动态分辨率支持(Dehghani等, 2024)。 · 多模态旋转位置嵌入（M-RoPE） · 统一图像和视频理解","doc_type":"web_page","link":"https://blog.csdn.net/v_JULY_v/article/details/145560246","title":"一文通透Qwen多模态大模型：从Qwen-VL、Qwen2-VL(提出 ..."},{"content":"模型名称. 版本. 上下文长度. 最大输入. 最大输出 ; 模型名称. 版本 · （Token数） ; qwen-max-2024-04-28. 又称qwen-max-0428. 快照版. 8,000. 6,000. 2,000.","doc_type":"web_page","link":"https://help.aliyun.com/zh/model-studio/models","title":"模型列表与价格_大模型服务平台百炼(Model Studio) - 阿里云文档"},{"content":"在本次发布的Qwen3模型中，我们注意到其LLM长上下文能力得到了显著提升。面对有限的算力资源，如何有效利用模型的长上下文能力，避免计算资源消耗呈指数级 ...","doc_type":"web_page","link":"https://newsroom.intel.com/zh-cn/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/%E8%8B%B1%E7%89%B9%E5%B0%94%E7%AC%AC%E4%B8%80%E6%97%B6%E9%97%B4%E6%B7%B1%E5%BA%A6%E4%BC%98%E5%8C%96qwen3%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%8D%87%E7%BA%A7ai-pc%E8%83%BD%E5%8A%9B%E8%B5%8B%E8%83%BD","title":"英特尔第一时间深度优化Qwen3大模型，升级AI PC能力赋能 ..."},{"content":"在最后阶段，我们使用高质量的长上下文数据将上下文长度扩展到32K token，确保模型能够有效地处理更长的输入。 由于模型架构的改进、训练数据的增加 ...","doc_type":"web_page","link":"https://qwenlm.github.io/zh/blog/qwen3/","title":"Qwen3：思深，行速| Qwen"},{"content":"长序列的训练需要大量的计算资源，因此团队采用了逐步扩展长度的方法，在多个阶段将Qwen2.5-1M的上下文长度从4K扩展到256K：. 团队从预训练的Qwen2.5的一个 ...","doc_type":"web_page","link":"https://www.qbitai.com/2025/01/249165.html","title":"Qwen开源首个长文本新模型，百万Tokens处理性能超GPT- ..."}],"Qwen 技术白皮书 架构细节 最新版本 论文":[{"content":"阿里Qwen 2.5 Max则宣称超越GPT-4o和DeepSeek V3在包括MMLU-Pro（更难版本）等关键基准上​。总体而言，新一代模型在MMLU上都进入了85-93%这一狭窄区间差距， ...","doc_type":"web_page","link":"https://zhuanlan.zhihu.com/p/1889837654448787699","title":"2025主流大语言模型深度对比"},{"content":"数学相关数据的增强让Qwen2-72B在GSM8K和MATH基准测试中分别比Qwen1.5-72B高出10.0和17.0个百分点。Qwen2-72B显示出与Llama-3-70B相当的推理能力 ...","doc_type":"web_page","link":"https://zhuanlan.zhihu.com/p/714655102","title":"Qwen2技术报告"},{"content":"... 测评中，通义千问2.0综合性能超过GPT-3.5，正在加速追赶GPT-4。以下是通义千问在MMLU、C-Eval、GSM8K、HumanEval、MATH等10个主流Benchmark测评集上的表现：.","doc_type":"web_page","link":"https://blog.csdn.net/aidashuju/article/details/142496107","title":"大模型之基准测试集(Benchmark)-给通义千问2.0做测评的10 ..."},{"content":"根据2025年最新研究数据，像MMLU这样曾经的权威基准，顶尖模型的准确率已经超过90%，基本失去了区分能力。这促使研究界不断创造更难、更全面、更\"人性化\"的 ...","doc_type":"web_page","link":"https://blog.csdn.net/hyc010110/article/details/150620821","title":"大模型评测体系深度解析：从能力基线到风险管理的完整指南"},{"content":"MT Bench也称为“多轮基准测试”, 是一种评估大型语言模型(LLM) 的方法。该基准测试提供了对LLM 性能的详细分析, 特别关注它们在多轮对话中管理对话流和遵循 ...","doc_type":"web_page","link":"https://note.iawen.com/note/llm/llm_test","title":"大模型LLM 的基准测试<一> - Iawen's Blog - 风无形，水无势"},{"content":"也因此，Qwen1.5-110B 在MMLU、TheoremQA、ARC-C、GSM8K、MATH 和HumanEval 等多个基准测评中不仅优于自家Qwen1.5-72B，更超越了Meta 的Llama-3-70B。","doc_type":"web_page","link":"https://m.aieva.cn/review/2223.html","title":"实测通义大模型2.5：闭源赶超GPT-4 Turbo"},{"content":"Qwen 团队对Qwen2 进行了全面评估，基本都优于竞品模型。Qwen2-72B-Instruct 在MT-Bench 得分为9.1，Arena-Hard 48.1，LiveCodeBench 35.7。Qwen2-72B-Base ...","doc_type":"web_page","link":"https://www.53ai.com/news/OpenSourceLLM/2024072306721.html","title":"最强开源大模型？Qwen2 技术报告解读"},{"content":"此外，在MATH、MMLU、MathVista等基准测试中，o1也刷新了SOTA。启用视觉感知能力后，o1在MMMU上取得了78.1%的成绩，成为第一个能与人类专家竞争的模型 ...","doc_type":"web_page","link":"https://www.bilibili.com/read/cv38689027","title":"全网都在吹的OpenAI最强模型o1，真能超越博士？我看未必..."},{"content":"MixEval和MMLU在稳定性上表现尤为突出，这体现在无论是使用贪心解码还是采样方法，其性能差异很小，且不同采样间的结果波动也很低。这种高度稳定性主要得益于 ...","doc_type":"web_page","link":"https://cloud.tencent.com/developer/news/1662751","title":"北京大学：利用好不确定性，8B小模型也能超越GPT-4 - 腾讯云"},{"content":"大语言模型是一种由包含数百亿个及以上参数的深度神经网络构建的语言模型，通常使用自. 监督学习方法通过大量无标注文本进行训练。2018 年 ...","doc_type":"web_page","link":"https://intro-llm.github.io/chapter/LLM-TAP-v2.pdf","title":"从理论到实践 - 大规模语言模型"}],"Qwen大模型 注意力机制优化 训练策略 超参数配置 2024":[{"content":"本项目不仅为想要深入了解大模型部署的技术人员提供了一条明确的实践路径，也为整个行业提供了一个高质量的参考案例。通过本项目的实施，可以预见到更多的 ...","doc_type":"web_page","link":"https://blog.csdn.net/laoyang360/article/details/150535053","title":"6G显存也能流畅运行大模型？实战Qwen量化部署原创"},{"content":"与传统的微调任务选择相比，Qwen 2.5 选择了更加多样化的任务，确保了模型在多个领域的适应性和泛化能力。这种多样化的任务选择使得模型在多种应用场景中表现出色。 数据选择 ...","doc_type":"web_page","link":"https://zhuanlan.zhihu.com/p/721084591","title":"QWen2.5 简单分析"},{"content":"特别是在泛化能力上，LLM已经不再局限于文本理解、摘要等简单下游任务，它还可以执行代码生成，甚至用思维链方式来分析问题。那么，很自然的一个想法就是，能否 ...","doc_type":"web_page","link":"https://developer.nvidia.com/zh-cn/blog/llm-agent-for-finance/","title":"基于大语言模型的Agent智能体在金融行业中的应用"},{"content":"大模型在应用中面临的局限性包括可靠性问题、逻辑推理能力不足、语义理解局限、可解释性和可调试性弱点，以及计算资源需求等方面。这些局限性直接影响 ...","doc_type":"web_page","link":"https://developer.aliyun.com/article/1571712","title":"大模型在应用中面临的局限性 - 阿里云开发者社区"},{"content":"今年的报告新增了对人工智能硬件发展状况. 的深入分析、对推理成本的新估算，以及对人工智能论文发表和专利申请趋势的新分析。我们还首次披露了企业采用负 ...","doc_type":"web_page","link":"https://hai.stanford.edu/assets/files/hai_ai_index_report_2025_chinese_version_061325.pdf","title":"介绍2025年人工智能指数报告 - Stanford HAI"},{"content":"Qwen 模型的多样化应用场景证明了其在自然语言生成与理解中的广泛适应性，为各行业的智能化和自动化提供了强大的支持。 7. Qwen 模型的局限性与挑战.","doc_type":"web_page","link":"https://blog.csdn.net/weixin_43114209/article/details/142697050","title":"深入解析Qwen 系列模型：核心技术、优势与未来应用前景"},{"content":"结合阿里云的DevOps工具，Qwen可以自动化地执行部署脚本、发布应用等任务。 ... 作为新模型，其稳定性与成本有待在实际业务中检验。 DeepSeek V3 ...","doc_type":"web_page","link":"https://zhuanlan.zhihu.com/p/1889837654448787699","title":"2025主流大语言模型深度对比"},{"content":"•Qwen-VL模型在实际应用中有哪些成功案例. •Qwen-VL模型如何处理图像和文本数据的 ... •Qwen 模型在实际应用中的可行性如何. •Qwen 模型的准确率如何与其他模型相比.","doc_type":"web_page","link":"https://blog.moontak.com/qwen%E9%80%9A%E4%B8%80%E5%8D%83%E9%97%AE%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1/","title":"Qwen(通义千问)知识图谱 - 月光AI博客"},{"content":"Lightblue使用阿里云通义千问(Qwen)支持其Karasu和Qarasu大语言模型的开发。Qwen拥有先进的架构并且针对东亚语言（尤其是日语）进行了广泛的训练。 科技 日本 中小企业 ...","doc_type":"web_page","link":"https://www.alibabacloud.com/zh/customers?_p_lc=1","title":"客户成功案例和案例研究——阿里云"},{"content":"本文通过“Qwen模型”实例，详细讲解了AI模型从微调到部署的全过程。涵盖模型简介、调参技巧、高效部署及实际案例，帮助读者从新手成长为调参高手， ...","doc_type":"web_page","link":"https://developer.aliyun.com/article/1641452","title":"【Qwen模型百变玩家】——从微调到部署的全能攻略！"}],"Qwen大模型 行业部署案例 量化分析 局限性 实际应用":[{"content":"重点包括：复杂的数据过滤和评分、精细化预训练数据配比、超参数优化、超长文预训练。 ... 对于1M token的序列，这种方法将注意力机制的计算负载减少了12.5倍 ...","doc_type":"web_page","link":"https://zhuanlan.zhihu.com/p/14710836610","title":"Qwen 2.5 技术报告（中文速通版）"},{"content":"表1列出了各模型的超参数及重要信息，例如预训练token数量. // ... 且为了充分发挥模型在长度外推方面的潜力，作者还采用了YARN机制（Peng等，2023）和双分块注意 ...","doc_type":"web_page","link":"https://blog.csdn.net/v_JULY_v/article/details/150444999","title":"一文通透Qwen LLM系列——从Qwen、Qwen1.5、Qwen2、 ..."},{"content":"首先，通过复杂的过滤和评分机制精心挑选高质量的训练数据，并结合战略性的数据混合。其次，对超参优化进行广泛的研究，以有效地训练各种规模的模型。最后， ...","doc_type":"web_page","link":"https://zhuanlan.zhihu.com/p/15421972162","title":"Qwen2.5 技术报告"},{"content":"在本报告中，我们介绍了Qwen2.5-1M系列模型，将上下⽂⻓度扩展到100万标记。与之. 前的128K版本相⽐，Qwen2.5-1M系列通过⻓上下⽂的预训练和后训练，显著增强了 ...","doc_type":"web_page","link":"https://download.s21i.co99.net/28254755/0/0/ABUIABA9GAAgqePUvQYo1r-r_wE.pdf?f=%E9%98%BF%E9%87%8C%E5%9B%A2%E9%98%9FQwen2.5-1M%E7%B3%BB%E5%88%97%E5%A4%A7%E6%A8%A1%E5%9E%8B%E6%8A%80%E6%9C%AF%E6%8A%A5%E5%91%8A.pdf&v=1739927977","title":"Qwen2.5-1M技术报告"},{"content":"Qwen3模型通过三个阶段进行预训练： (1) 一般阶段（S1）：在第一个预训练阶段，所有Qwen3模型都在序列长度为4,096个标记的数据上进行训练，使用超过30万亿个标记 ...","doc_type":"web_page","link":"https://blog.csdn.net/u013524655/article/details/148201461","title":"Qwen3 技术报告原创"},{"content":"为了提高计算效率并减少内存使用，在注意力模块中采用了闪存注意力机制（Flash Attention）。模型采用标准优化器AdamW 进行预训练优化，超参数设置为 ...","doc_type":"web_page","link":"https://www.drinkingfishingseeking.com/2025/01/06/llm-qwen/","title":"LLM：Qwen 系列- 瓦尔登湖小酒馆| OAA的博客"},{"content":"为了充分利用模型的外推潜力，Qwen2 采用了YARN 机制和双块注意力机制DCA。这些策略使模型能够处理长达131,072 个token 的序列，同时保持高性能。 三、后 ...","doc_type":"web_page","link":"https://www.maas.com.cn/blog/448.html","title":"阿里大模型Qwen2技术报告解读"},{"content":"大语言模型是一种由包含数百亿个及以上参数的深度神经网络构建的语言模型，通常使用自. 监督学习方法通过大量无标注文本进行训练。2018 年 ...","doc_type":"web_page","link":"https://intro-llm.github.io/chapter/LLM-TAP-v2.pdf","title":"从理论到实践 - 大规模语言模型"},{"content":"团队遵循Qwen2.5的做法，使用ABF技术将RoPE的基础频率从10,000增加到1,000,000。同时，他们引入了YARN和双块注意力（Dual Chunk Attention，DCA）技术，在推理 ...","doc_type":"web_page","link":"https://view.inews.qq.com/a/20250514A0683S00","title":"Qwen3模型：思考模式与非思考模式的完美融合"},{"content":"与Qwen2.5（杨等，2024b）类似，我们根据上述三个预训练阶段开发了最优超参数（如学习率调度器和批量大小）预测的缩放定律。通过广泛的实验，我们系统地研究了 ...","doc_type":"web_page","link":"https://www.cnblogs.com/emergence/p/18877115","title":"Qwen3 技术报告- 一介布衣"}],"Qwen MMLU GSM8K 评测基准 SOTA对比 性能分析":[{"content":"by A Yang · 2025 · Cited by 2895 — In this work, we present Qwen3, the latest version of the Qwen model family. Qwen3 comprises a series of large language models (LLMs) designed ...","doc_type":"web_page","link":"https://arxiv.org/abs/2505.09388","title":"[2505.09388] Qwen3 Technical Report"},{"content":"本次更新的首个亮点是技术架构与性能提升，新版本在底层架构上虽未公开. 细节，但实测表现显示其核心改进集中在三方面：. •. ​ ​ 编程能力​ ​ ：在 ...","doc_type":"web_page","link":"https://cnpsec.com/plat_files/upload/png_upload/20250610/202506101749535215303.pdf","title":"谷歌更新Gemini 2.5 Pro，阿里开源Qwen3 新模型"},{"content":"by A Yang · 2024 · Cited by 2895 — Abstract:In this report, we introduce Qwen2.5, a comprehensive series of large language models (LLMs) designed to meet diverse needs.","doc_type":"web_page","link":"https://arxiv.org/abs/2412.15115","title":"[2412.15115] Qwen2.5 Technical Report"},{"content":"在这项工作中，我们介绍了QWEN，我们大型语言模型系列的第一个版本。QWEN是一个全面的语言模型系列，包括参数数量不同的不同模型。它包括QWEN，基础预训练语言 ...","doc_type":"web_page","link":"https://zhuanlan.zhihu.com/p/685633623","title":"阿里通义千问完整技术报告"},{"content":"Qwen-2的微调过程遵循了一个关键原则，即在尽可能扩大训练规模的同时，减少对人工标注的依赖。Qwen-2探索了多种自动化的方法来获取高质量、可靠且具有创造性 ...","doc_type":"web_page","link":"https://blog.csdn.net/AIGCmagic/article/details/139692335","title":"AI多模态模型架构之LLM主干(2)：Qwen系列原创"},{"content":"本期则会详细介绍一下另外一个在多模态大模型领域相当优秀的工作Qwen-VL，同时Qwen2-VL的技术报告在8月29号刚刚发布，也会跟大家同步介绍这个最新的工作。同样地我并不会过多 ...","doc_type":"web_page","link":"https://developer.volcengine.com/articles/7413673495890296843","title":"多模态大模型: 盘点&Highlights part2——Qwen-VL系列- 文章"},{"content":"近年来，在Transformer 架构基础上构建的预训练语言模型为自. 然语言处理领域带来了一系列突破式进展，成为人工智能主流技术范. 式。预训练语言模型采用“预训练+微调”方法， ...","doc_type":"web_page","link":"https://13115299.s21i.faiusr.com/61/1/abuiaba9gaagma6kqqyo-z7d8wi.pdf","title":"中国人工智能系列白皮书——大模型技术（2023 版）"},{"content":"论文首先介绍了Qwen2模型的设计和评估方法，然后介绍了在多个基准数据集上的性能表现，最后提供了模型的开放资源和应用。 重点思路. 模型设计. 分词器：继 ...","doc_type":"web_page","link":"https://blog.csdn.net/weixin_46739757/article/details/141535129","title":"阿里：千问2技术报告发布！ 原创"},{"content":"2024年6月16日，阿里巴巴Qwen团队对外宣布，推出支持苹果MLX架构的Qwen3 模型，包含4种精度，用户可以根据硬件资源选择合适的模型。搭载对应芯片的苹果设备可以更流畅、更高效 ...","doc_type":"web_page","link":"https://www.yfchuhai.com/article/10225665.html","title":"苹果AI新进展：Qwen3已全面“登陆”苹果MLX框架"},{"content":"2024年我花了快六个月的时间，系统化整理归纳了深度学习在工业视觉、机器视觉、智能智造行业应用的关键知识点，基于这些关键知识点构建了一个深度学习 ...","doc_type":"web_page","link":"https://www.eet-china.com/mp/a436513.html","title":"深度学习系统化学习路线图专题(2025版本)"}]}