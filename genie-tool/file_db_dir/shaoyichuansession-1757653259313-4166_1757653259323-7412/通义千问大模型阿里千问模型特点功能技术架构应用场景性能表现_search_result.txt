{"通义千问 训练策略 超参数 数据配比 数据规模":[{"content":"如果我们采用顺序微调的策略，比如先用代码数据训练，再用数学数据训练，最后用通用数据训练，模型在学习新知识时，很容易忘记之前学到的技能。当模型完成通用 ...","doc_type":"web_page","link":"https://zhuanlan.zhihu.com/p/1944002824263407495","title":"大模型SFT数据配比的一些实践启示"},{"content":"与Qwen2.5 类似，我们基于上述三个预训练阶段，建立了用于预测最优超参数（hyper-parameters ，如学习率调度器和batch批量大小等)的扩展规律（scaling laws）。","doc_type":"web_page","link":"https://zhuanlan.zhihu.com/p/1906057666490507847","title":"Qwen3技术报告首次全公开！“混合推理模型”是这样炼成的"},{"content":"作为阿里云通义千问系列模型，Qwen提供了丰富的微调选项，其中学习率（Learning Rate）和批次大小（Batch Size）是两个最为关键的超参数。本文将深入探讨Qwen ...","doc_type":"web_page","link":"https://blog.csdn.net/gitblog_00770/article/details/151165209","title":"Qwen超参数调优：学习率与批次大小的优化"},{"content":"本文档以通义千问模型的微调操作为例进行说明，使用命令行（Shell）和API （HTTP）两种方式，帮助您使用百炼提供的模型微调功能。","doc_type":"web_page","link":"https://help.aliyun.com/zh/model-studio/fine-tuning-api-guide","title":"模型调优操作_大模型服务平台百炼(Model Studio) - 阿里云文档"},{"content":"阿里云百炼提供添加混合训练数据功能，您可以将您的训练数据与千问通用多领域、多行业、多场景数据混合训练，从而提高训练效果避免模型基础能力的遗失。","doc_type":"web_page","link":"https://help.aliyun.com/zh/model-studio/model-training-on-console","title":"在控制台进行模型调优 - 阿里云文档"},{"content":"超参数配置：训练算法支持的超参信息如下，您可以根据使用的数据，计算资源等调整超参，或是使用算法默认配置的超参。 超参数. 类型. 默认值. 是否必须.","doc_type":"web_page","link":"https://www.alibabacloud.com/help/zh/pai/use-cases/deploy-and-fine-tune-qwen-1-5-models","title":"通义千问1.5模型部署与微调- 人工智能平台PAI - 阿里云"},{"content":"首先，我们通过复杂的筛选和评分机制精心策划高质量的训练数据，并结合策略性的数据混合。其次，我们对超参数优化进行广泛研究，以便有效地训练不同规模的模型 ...","doc_type":"web_page","link":"https://blog.csdn.net/qq_22337877/article/details/144756377","title":"大模型-Qwen2.5 技术报告解读"},{"content":"您可以在PAI-Model Gallery中使用预置的教师大语言模型（通义千问2-72B-Instruct）对训练数据集中的指令生成回复，从而将对应教师大模型的知识进行蒸馏。","doc_type":"web_page","link":"https://www.alibabacloud.com/help/zh/pai/use-cases/llm-data-enhancement-and-model-distillation-solution","title":"人工智能平台PAI：大语言模型数据增强与模型蒸馏解决方案"},{"content":"在预训练时必须使用全参数训练，但在增量训练中主要使用部分参数训练。 增量预训练与预训练相比，在训练数据上预训练数据量更大、无需标注，强调多样性，而CPT ...","doc_type":"web_page","link":"https://wqw547243068.github.io/llm_train","title":"LLM 大模型训练之路 - 鹤啸九天"},{"content":"4. 训练超参数 · 批次大小（Batch Size）、学习率（Learning Rate） 和训练轮数（Epochs）: 这些超参数与模型的收敛速度和过拟合风险密切相关。 · 多任务预训练和 ...","doc_type":"web_page","link":"https://blog.moontak.com/id/542822/","title":"Qwen-VL模型的超参数设置对性能有何影响 - 月光AI博客"}],"通义千问 最新技术报告 模型卡 开源实现":[{"content":"... 千亿级参数大模型通义千问2.0。据现场介绍，在10个权威测评中，通义千问2.0综合性能超过GPT-3.5，正在加速追赶GPT-4。以下是通义千问在MMLU、C-Eval ...","doc_type":"web_page","link":"https://blog.csdn.net/aidashuju/article/details/142496107","title":"大模型之基准测试集(Benchmark)-给通义千问2.0做测评的10 ..."},{"content":"C-Eval/MMLU准确率, 标准化评测. 推理能力, GSM8K准确率, 数学问题解决. 代码能力, HumanEval Pass@1, 代码生成质量. 效率指标, 推理速度(tokens/s), 性能 ...","doc_type":"web_page","link":"https://blog.csdn.net/gitblog_01151/article/details/151163047","title":"通义千问Qwen学术研究：论文复现与实验设计"},{"content":"选项：常见于分类任务，判断题以及选择题，目前这类问题的数据集占比最大，有MMLU, CEval 数据集等等，评估标准一般使用准确率–ACCEvaluator。 短语：常见于问答 ...","doc_type":"web_page","link":"https://zhuanlan.zhihu.com/p/692725726","title":"实战AI大模型通用能力评测"},{"content":"简介：通义千问是阿里云研发的通义千问大模型系列。其中，Qwen-3是阿里云通义实验 ... 在标准的中文和英文权威benchmark（C-EVAL/MMLU）上均取得同尺寸最好的效果。","doc_type":"web_page","link":"https://github.com/HqWu-HITCS/Awesome-Chinese-LLM","title":"HqWu-HITCS/Awesome-Chinese-LLM: 整理开源的 ..."},{"content":"最值得注意的是MMLU 这个数据集，它考虑了57 个学科，从人文到社科到理工多个大类的综合知识能力。DeepMind 的Gopher 和Chinchilla 这两个模型甚至只看MMLU ...","doc_type":"web_page","link":"https://yaofu.notion.site/C-Eval-6b79edd91b454e3d8ea41c59ea2af873","title":"C-Eval: 构造中文大模型的知识评估基准"},{"content":"PAI-QuickStart提供LLM评测功能，可基于权威公开数据集（CMMLU/C-Eval/MMLU等），或自定义数据集，进行模型综合能力的评估，判断模型能力是否适合自身业务场景，并提供多模型性能 ...","doc_type":"web_page","link":"https://www.alibabacloud.com/help/zh/pai/product-overview/feature-release-notes","title":"功能发布记录- 人工智能平台PAI - 阿里云"},{"content":"关于C-Eval. C-Eval 是一个全面的中文基础模型评估套件。它包含了13948个多项选择题，涵盖了52个不同的学科和四个难度级别，如下所示。您可以在探索 中查看我们的数据集 ...","doc_type":"web_page","link":"https://cevalbenchmark.com/index_zh.html","title":"一个适用于大语言模型的多层次多学科中文评估套件"},{"content":"在中文常识能力测评基准C-Eval 上，通义千问在验证集和测试集中都是得分最高的7B 开源模型，展现了扎实的中文能力。 在数学解题能力评测GSM8K、代码能力评测 ...","doc_type":"web_page","link":"https://developer.aliyun.com/article/1301082","title":"免费、可商用，阿里云开源70亿参数通义千问大模型"},{"content":"近日，AI模型社区魔搭上架两款开源模型QWen-7B和QWen-7B-Chat，阿里云确认其为通义千问70亿参数通用模型和对话模型，两款模型均开源、免费、可商用。","doc_type":"web_page","link":"https://www.zhihu.com/question/615428959/answer/3150033947","title":"阿里云宣布开源通义千问70亿参数大模型"},{"content":"简介：通义千问是阿里云研发的通义千问大模型系列模型，包括参数规模为18亿（1.8B ... 的中文和英文权威基准（C-EVAL/MMLU）上均取得同尺寸最好的效果。 百川2.","doc_type":"web_page","link":"https://docs.feishu.cn/v/wiki/MG1twroJpiEJBPkDQA9cboJ8ntf/ac","title":"LLaMA相关中文模型的优势在哪？"}],"通义千问 模型架构 Transformer 注意力机制 技术细节":[{"content":"为了进一步验证预训练的结果，研究员们基于上述训练的基. 础模型进行了推理微调对比实验。该模型在数学领域上取得了与. DeepSeekmath7B 相当的成绩，在数学基准上的准确率均 ...","doc_type":"web_page","link":"https://www.microsoft.com/en-us/research/wp-content/uploads/2025/03/matrix71.pdf","title":"01 焦点02 前沿求索"},{"content":"第三部分 QwQ-32B：阿里千问团队推出的推理大模型. 25年3.6日，阿里千问团队推出了QwQ-32B，他们在冷启动的基础上开展了大规模强化学习，其大小虽然 ...","doc_type":"web_page","link":"https://blog.csdn.net/v_JULY_v/article/details/145289228","title":"一文速览推理模型DeepSeek R1：如何通过纯RL训练以比肩 ..."},{"content":"本指南涵盖了基础知识、法律法规、经典AI模型、漏洞与攻击、防御方法、安全开发与运维、相关框架、会议讲座以及实践实验室等多个方面，并为每个层级提供了的学习建议和资源 ...","doc_type":"web_page","link":"https://github.com/Acmesec/theAIMythbook","title":"Ai迷思录（应用与安全指南）"},{"content":"... 实验者通对比针刺大鼠“足三里”. 穴位前后穴区局部肥大细胞脱颗粒率，发现针刺镇痛效应与穴区肥大细胞脱. 颗粒率呈正相关关系，推测肥大细胞脱颗粒参与了针刺镇痛效应的 ...","doc_type":"web_page","link":"https://scholar.harvard.edu/files/ctang/files/healthcare_big_data_draft_in_chinese.pdf","title":"第1 章医疗的大数据时代"},{"content":"在准备中文书的过程中，我们广泛阅读了现有的经典论文、相关代码和教材，. 从中提炼出核心概念、主流算法与模型，并进行了系统性的组织与介绍。我们对于. 每 ...","doc_type":"web_page","link":"https://llmbook-zh.github.io/LLMBook.pdf","title":"LLMBook.pdf - 大语言模型"}],"通义千问 性能评测 MMLU C-Eval 标准化协议":[{"content":"Transformer模型的注意力机制在上下文长度上有很大的限制，模型会随着上下文长度的增加，计算成本和内存会成倍增加。Qwen模型利用了简单地非训练计算 ...","doc_type":"web_page","link":"https://zhuanlan.zhihu.com/p/658392609","title":"通义千问-Qwen技术报告细节分享"},{"content":"Qwen2的核心改进包括采用新的分词器、优化的Transformer架构（如Dual Chunk Attention和Grouped Query Attention内容概要）、大规模高质量预：本文介绍了Q ...","doc_type":"web_page","link":"https://blog.csdn.net/gitblog_00074/article/details/151162610","title":"Qwen模型架构解析：Transformer创新的技术细节"},{"content":"1.4 上下文长度扩展​ Transformer 模型的注意力机制在上下文长度方面存在显著限制。 随着上下文长度的增加，二次复杂度计算会导致计算和内存成本急剧增加， ...","doc_type":"web_page","link":"https://zhuanlan.zhihu.com/p/675332872","title":"Qwen 通义千问模型拓扑结构解析"},{"content":"说到注意力机制就不得不提到Q、K、V三板斧。多头注意力机制通过将输入分割为多个头，然后对每个头进行自注意力，最后再进行合并。实现多头注意力机制。 ... 在 ...","doc_type":"web_page","link":"https://blog.csdn.net/2302_80236633/article/details/146280085","title":"Qwen2.5的注意力秘籍：解锁高效模型的钥匙，分组查询 ..."},{"content":"这个简短的介绍提到Qwen2是基于Transformer架构，采用SwiGLU激活、注意力QKV偏置、组查询注意力、滑动窗口注意力和全序列注意力相混合等技术，根据介绍， ...","doc_type":"web_page","link":"https://www.pingwest.com/a/292118","title":"Hugging Face剧透：阿里通义千问下一代Qwen2来了？"},{"content":"自注意力机制：动态计算序列中任意元素的关联权重（如判断句子中代词指代对象），解决长距离依赖问题[3]。 · 并行化训练：支持对整个序列并行计算，使千亿级参数 ...","doc_type":"web_page","link":"https://www.cndba.cn/dave/article/131712","title":"大模型中Transformer 架构说明-- cnDBA.cn"},{"content":"本文是使用Transformers 推理LLM 技术细节的第2 篇文章，我们将基于Qwen2.5 大模型，通过模型配置和 from_pretrained 代码，了解AutoModel模型初始化的技术 ...","doc_type":"web_page","link":"https://www.cnblogs.com/obullxl/p/18508576/NTopic2024102601","title":"transformers 推理Qwen2.5 等大模型技术细节详解(二) ..."},{"content":"第一，Transformer是既MLP、RNN、CNN之后的第四大特征提取器，也被称为第四大基础模型；最近爆火的chatGPT，其最底层原理也是Transformer，Transformer的重要性可见一斑。 第二， ...","doc_type":"web_page","link":"https://developer.volcengine.com/articles/7382324355448963081","title":"Transformer的细节到底是怎么样的？Transformer 连环18问！"},{"content":"交叉注意力在Transformer模型中主要用于解码器部分，将解码器的输出与编码器的输出进行交互，以获取上下文信息。在这种机制中，查询（Q）通常来自解码器的输出， ...","doc_type":"web_page","link":"https://blog.moontak.com/id/541688/","title":"如何在Transformer模型中实现交叉注意力 - 月光AI博客"},{"content":"多头注意力机制将查询、键和值矩阵分成多个头（即多个子空间），每个头具有不同的线性变换参数。每个头独立地计算注意力得分，并生成一个注意力加权后的输出。","doc_type":"web_page","link":"https://developer.aliyun.com/article/1649746","title":"深入剖析Transformer架构中的多头注意力机制"}],"通义千问 官方基准对比 消融实验 复现代码":[{"content":"Qwen又立功，全球最快开源模型诞生，超2000 tokens/秒. 技术报告也已发布. 从体量上来看，K2 Think仅有32B，但官方却表示，它已经可以与 ...","doc_type":"web_page","link":"https://www.qbitai.com/2025/09/330285.html","title":"Qwen又立功，全球最快开源模型诞生，超2000 tokens/秒！"},{"content":"4月29日，阿里巴巴正式发布新一代通义千问大模型Qwen3，包含6款稠密模型 ... 在硬件协同上，MoE模型仅需4张H20加速卡，便能实现235B旗舰模型的部署。","doc_type":"web_page","link":"https://zhuanlan.zhihu.com/p/1906093620689376627","title":"Qwen3技术报告公开！235B模型性能居开源模型榜首"},{"content":"记者获悉，阿里巴巴旗下通义千问已推出Qwen3-Max-Preview（Instruct），参数量达到1T，为其迄今为止最大的模型，在中英文理解、复杂指令遵循、工具调用等维度 ...","doc_type":"web_page","link":"https://wap.eastmoney.com/a/202509063506466398.html","title":"阿里通义千问发布迄今最大模型——Qwen3-Max-Preview"},{"content":"简介： 近日，通义千问Qwen3系列模型已开源，其技术报告也正式发布。Qwen3系列包含密集模型和混合专家（MoE）模型，参数规模从0.6B到235B不等。","doc_type":"web_page","link":"https://developer.aliyun.com/article/1666422","title":"Qwen3技术报告首次全公开！“混合推理模型”是这样炼成的"},{"content":"Qwen3是一系列开源权重大型语言模型（LLMs），在各种任务和领域中实现了最先进的性能。 我们发布了密集模型和专家混合（MoE）模型，参数范围从0.6亿到235亿，以 ...","doc_type":"web_page","link":"https://blog.csdn.net/u013524655/article/details/148933584","title":"通义千问3技术报告原创"},{"content":"9月6日凌晨，阿里巴巴旗下通义千问（Qwen）在其官网发布Qwen3-Max-Preview（Instruct）——一款参数量超过1万亿的预览版超大型模型。 阿里对外称，该模型在中英文 ...","doc_type":"web_page","link":"https://wallstreetcn.com/articles/3755069","title":"赛道Hyper | 通义千问万亿模型的战略突围解析"},{"content":"通义千问大模型开源闭源两手抓，已代表了中国大模型的技术新高度。Qwen3-Max-Preview刷新了阿里大模型参数新纪录，其试图用更加强悍的性能，证明规模 ...","doc_type":"web_page","link":"https://www.cnbeta.com.tw/articles/tech/1523090.htm","title":"超1万亿参数阿里史上最大最强模型免费上线几秒完成程序员 ..."},{"content":"一、开源大模型新标杆. Qwen2 是阿里云通义千问团队于2024 年5 月开源的新一代大语言模型系列，包含0.5B/1.5B/7B/57B/72B 五个参数版本。 · 二、突破性特性.","doc_type":"web_page","link":"https://juejin.cn/post/7540592011155357742","title":"Qwen2-阿里云最新发布的通义千问开源大模型"},{"content":"通义千问 - Qwen3 - Coder​​ 基于Qwen3的代码生成模型，具有强大的Coding Agent能力，擅长工具调用和环境交互，实现自主编程同时兼具通用能力。","doc_type":"web_page","link":"https://www.aliyun.com/benefit/scene/qwen","title":"智启通义千问3 模力全开"},{"content":"基于多语言优化架构，新增27 种语言支持，显著提升代码与数学推理能力，最高支持128K 上下文长度（Qwen2-72B-Instruct）。模型采用分组查询注意力机制，在保持 ...","doc_type":"web_page","link":"https://blog.csdn.net/Qynwang/article/details/150581468","title":"Qwen2-阿里云最新发布的通义千问开源大模型原创"}]}