{"性能对比 MMLU MMBench 得分分析":[{"content":"作为多模态大模型集成框架，这个项目适用于任何需要处理和生成涉及图像和文本的场景，例如：. 图像描述生成; 图像问答; 语义理解与定位; 对话系统中的视觉 ...","doc_type":"web_page","link":"https://zhuanlan.zhihu.com/p/1905197122770429119","title":"【多模态大模型】多模态界的transformers-Prismatic VLMs"},{"content":"模型的实际应用。现在OpenVLA来了，训练他所采用的数据是现实中真正机器人操作的视频/动作记录，不是模拟器中产生的数据。 继续访问. 斯坦福提出首个 ...","doc_type":"web_page","link":"https://blog.csdn.net/v_JULY_v/article/details/145072593","title":"一文通透OpenVLA——在Prismatic VLM(SigLIP、DinoV2、 ..."},{"content":"论文的核心方法是实验驱动的设计空间探索。作者首先建立了一个灵活的VLM 训练框架，然后系统地改变VLM 的各个组成部分（例如视觉backbone，语言模型，训练方式），并使用标准化的 ...","doc_type":"web_page","link":"https://www.themoonlight.io/zh/review/prismatic-vlms-investigating-the-design-space-of-visually-conditioned-language-models","title":"[论文审查] Prismatic VLMs: Investigating the Design Space ..."},{"content":"这篇文章基于LLaVA 1.5 的框架，对于视觉大语言模型(Vison Language Model) 的训练、架构等设计方案进行了消融实验。通过在一系列视觉语言的测试集上 ...","doc_type":"web_page","link":"https://blog.csdn.net/alxe_made/article/details/140800495","title":"VLM系列文章4-Prismatic VLMs 原创"},{"content":"视觉条件语言模型（VLM）在视觉对话、场景理解和机器人任务规划等应用中得到了越来越广泛的应用，这种应用推动了LLaVa、InstructBLIP和PaLI-3等大量新模型 ...","doc_type":"web_page","link":"https://hub.baai.ac.cn/paper/1eb16f5d-df43-42cc-9f44-41abd872fd84","title":"Prismatic VLMs: Investigating the Design Space of Visually ..."},{"content":"主要进展包括架构创新、参数高效训练策略以及实时推理加速。我们深入探讨了VLA在多样化应用领域的落地，如人形机器人、自动驾驶、医疗与工业机器人、精准 ...","doc_type":"web_page","link":"https://www.cnblogs.com/emergence/p/19043338","title":"【综述】VLA模型：概念、进展、应用与挑战"},{"content":"初步的统一多模态模型探索受到BERT启发，从表征学习的角度. 出发构建能为不同下游任务提供有效初始化的多模态预训练模型，这类方法尽管有效. 但仍然在泛用性方面受限于预训练 ...","doc_type":"web_page","link":"https://aclanthology.org/2024.ccl-2.1.pdf","title":"从多模态预训练到多模态大模型:架构、训练、评测、趋势概览"},{"content":"FiS-VLA 提出一种创新结构，将VLM 的末端几层Transformer 模块直接重构为系统1 执行模块，嵌入原有系统2 内部，形成一个统一的高效推理与控制模型。","doc_type":"web_page","link":"https://cj.sina.cn/articles/view/5953190046/162d6789e06701tkp2?froms=ggmp","title":"模拟大脑功能分化！北大与港中文发布Fast-in-Slow VLA"},{"content":"Moxin VLM 基于Prismatic VLMs 框架构建：. 视觉编码器： 结合DINOv2（低层空间特征）和SigLIP（高层语义特征）提升图像理解。 语言模型：","doc_type":"web_page","link":"https://www.xugj520.cn/archives/moxin7b-architecture-context-processing.html","title":"Moxin 7B开源大模型架构揭秘：36层Transformer设计与32K ..."},{"content":"AutoGLM 2.0由国产模型GLM-4.5和GLM-4.5V驱动，具备推理、代码与多模态能力，可完成多样化任务，如在生活场景中操作美团、京东等应用，或在办公场景中完成全流程工作。 来源：智 ...","doc_type":"web_page","link":"https://www.yepaisz.com/260.html","title":"每日AI简报- 野湃AI"}],"轻量级视觉语言模型 7B参数 方法综述":[{"content":"评价指标包括：Chatbot Arena匿名对战的人类偏好得分、MT-Bench GPT-4判分，以及模型在知识问答基准（如MMLU）上的成绩klu.ai。由于问题设置包含复杂的追问和 ...","doc_type":"web_page","link":"https://zhuanlan.zhihu.com/p/27558266660","title":"LLM 相关Benchmark综述报告 - 知乎专栏"},{"content":"在MMBench评测中，MiniCPM-V-2的综合得分表现优异，尤其是在多模态任务上的表现，显示出其在图像理解、文本生成等多方面的均衡能力。 横向性能对比.","doc_type":"web_page","link":"https://blog.csdn.net/gitblog_02754/article/details/149874752","title":"MiniCPM-V-2性能报告：MMLU= 核心性能跑分数据的惊人表现意味着 ..."},{"content":"利用思维链（CoT）推理的模型在MMLU-Pro 上的表现优于直接作答，这与原始MMLU 上的发现形成鲜明对比，表明MMLU-Pro 包含了更多复杂的推理问题. BIG-Bench Hard (BBH) (Suzgun ...","doc_type":"web_page","link":"https://zhuanlan.zhihu.com/p/24824614963","title":"大模型常用的benchmark - 知乎专栏"},{"content":"2025 年主流大模型性能对比与选型指南数据集 · 本数据集深度对比30 + 主流大模型，包含12 项核心指标与5 大场景分析，为AI 开发者、企业及研究人员提供科学 ...","doc_type":"web_page","link":"https://blog.csdn.net/weixin_43431218/article/details/135631534","title":"【大模型评测】常见的大模型评测数据集_mmlu数据集 - CSDN博客"},{"content":"例如，一个在MMLU基准上训练的模型可能在MMLU得分上表现很高，但实际用途不大。 ... Elo评分系统通过比较双方当前评分计算预期胜率，并根据实际比赛结果调整评分，从而 ...","doc_type":"web_page","link":"https://ai.gaozhijun.me/5-Projects/evaluating-llms.html","title":"大模型的评估与选择 - 人工智能实践(语言)"},{"content":"MMLU 是2021 年提出的dataset，三年過去了，原本的MMLU 對很多模型來說變得太容易。很多模型現在在MMLU上達到了人類基準性能，這種現象被稱為飽和。 image 可以從上圖發現有 ...","doc_type":"web_page","link":"https://ithelp.ithome.com.tw/articles/10362484","title":"[Day18] 如何選擇適合特定任務的LLM？深入分析評測LLM ... - iT 邦幫忙"},{"content":"本页面提供了当前主流大模型在各评测数据集上的综合评测结果。汇总了最新的模型表现榜单，帮助研究者和开发者了解不同模型在各种数据集上的性能。进入，发现，和对比各 ...","doc_type":"web_page","link":"https://www.datalearner.com/ai-models/leaderboard/datalearner-llm-leaderboard","title":"大模型综合能力评测对比表 - DataLearner AI"},{"content":"當將「普通」資料集上的模型效能與修改後的問題進行比較時，他們發現效能下降，例如GPT-4 在普通MMLU 問題上得分為84.4，在修改後的MMLU 問題上得分為68.86 [ ...","doc_type":"web_page","link":"https://ai.choozmo.com/blog/what-is-mmlu-dataset/","title":"MMLU 是什麼"},{"content":"对于多模态大模型，. LLaVA-Bench、VisIT-Bench、MMBench 等使用较为广泛。 表1 ... 示在MMLU 上的得分率高于GPT-4。但通过分析谷歌发布的技术报. 告《Gemini: A ...","doc_type":"web_page","link":"https://www.caict.ac.cn/kxyj/qwfb/ztbg/202407/P020240711534708580017.pdf","title":"[PDF] 大模型基准测试体系研究报告(2024 年)"},{"content":"MT Bench也称为“多轮基准测试”, 是一种评估大型语言模型(LLM) 的方法。该基准测试提供了对LLM 性能的详细分析, 特别关注它们在多轮对话中管理对话流和遵循 ...","doc_type":"web_page","link":"https://note.iawen.com/note/llm/llm_test","title":"大模型LLM 的基准测试<一> - Iawen's Blog - 风无形，水无势"}],"小型视觉语言模型 部署案例 最新研究":[{"content":"首先，阐述VLM 的定义、工作原理及训练方法；随后，介绍并讨论评估VLM 的各类方法。虽然本文主要聚焦于图像到语言的映射，亦对视觉语言模型向视频领域的扩展进行了探讨。 一.","doc_type":"web_page","link":"https://zhuanlan.zhihu.com/p/1921222449275602562","title":"视觉语言模型综述—《An Introduction to Vision-Language ... - 知乎专栏"},{"content":"Fine-Tuning：介绍了多种提高大语言模型微调效率的方法，包括参数高效微调、全参数微调等。其中，参数高效微调通过引入轻量级适配器模块来减少微调参数的数量 ...","doc_type":"web_page","link":"https://zhuanlan.zhihu.com/p/699033863","title":"探索高效多模态大语言模型的奥秘：综述与展望 - 知乎专栏"},{"content":"Dolphin 采用了一个0.5B 参数的紧凑型解码器，将大量上下文信息提炼到内存嵌入中，从而大大减少了主要7B 参数解码器模型的输入长度。 ... 他们通过一种轻量级微调技术实现了这 ...","doc_type":"web_page","link":"https://docs.feishu.cn/v/wiki/CzomwHIV2ii70Lkpkg5cPOIknmh/aa","title":"Hugging Face构建VLM教程：更好理解视觉语言模型 - 飞书文档"},{"content":"摘要：视觉语言模型在零-小样本分类、图文检索、图像字幕、视觉问答和视觉定位等多种多模态任务上取得. 了显著的进展。然而，大多数方法依赖于通用数据集的预训练， ...","doc_type":"web_page","link":"https://www.ygxb.ac.cn/rc-pub/front/front-article/download/117459049/lowqualitypdf/%E7%94%A8%E4%BA%8E%E9%9B%B6%E6%A0%B7%E6%9C%AC%E5%88%86%E7%B1%BB%E7%9A%84%E9%81%A5%E6%84%9F%E8%A7%86%E8%A7%89%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%EF%BC%9A%E7%BB%BC%E8%BF%B0.pdf","title":"[PDF] 用于零样本分类的遥感视觉语言模型：综述 - 遥感学报"},{"content":"第2节重点介绍模型架构，包括轻量级设计、高效的自注意力近似和神经架构搜索，以有效地构建更小的模型。第3节涵盖了有效的预训练和微调技术，以提高性能的SLM ...","doc_type":"web_page","link":"https://blog.csdn.net/qq_29868553/article/details/144317029","title":"小语言模型综述（A Survey of Small Language Models）-全文中文翻译"},{"content":"当前主流的开源视觉语言模型通常表现出色，这通常依赖于背后不少于7B参数的语言模型组件。 ... 1）一个视觉编码器，2）一个轻量级语言模型（LLM），以及3）一个负责对齐视觉和 ...","doc_type":"web_page","link":"https://cloud.tencent.com/developer/article/2434809","title":"Xmodel-VLM | 多模态视觉语言模型，解决高成本难题，实现高效部署！"},{"content":"该模型总共80亿参数，每个输入token仅激活20亿参数，与Llama2-7B相比，减少了约70%的推理计算。 MoE架构为在边缘设备上部署大语言模型提供了创新解决方案。这些方法利用稀疏 ...","doc_type":"web_page","link":"https://developer.volcengine.com/articles/7433674165921513523","title":"万字长文细说端侧大模型进展(综述) - 文章- 开发者社区- 火山引擎"},{"content":"其次，这种视觉编码器在预训练时的对齐目标通常是参数量较小的语言模型，而在LVLMs中，视觉特征需要服务于参数量在7B及以上的LLMs. 这种规模差异加大了视觉特征与LLMs ...","doc_type":"web_page","link":"https://crad.ict.ac.cn/article/cstr/32373.14.issn1000-1239.202440444","title":"视觉语言大模型的幻觉综述：成因、评估与治理 - 计算机研究与发展"},{"content":"1月24日，Hugging Face 发布了两款全新轻量级视觉语言模型（VLM）：SmolVLM-256M 和 SmolVLM-500M。它们是SmolVLM 家族的成员，接受图像和文本输入的任意 ...","doc_type":"web_page","link":"https://blog.csdn.net/u012744245/article/details/145629058","title":"Hugging Face最小AI视觉语言模型登场！百川智能开源Baichuan-M1 ..."},{"content":"本节解构了驱动现代大型语言模型（LLM）的核心架构范式。我们将从基础的Transformer模型入手，分析其固有的局限性，然后系统地探索为应对这些挑战而涌现的 ...","doc_type":"web_page","link":"https://www.cnblogs.com/sddai/p/18959810","title":"大型语言模型（LLM）技术综述 - 博客园"}],"模型架构创新 Prismatic VLMs 实际应用":[{"content":"我们通常将参数量少于20亿（2B）且能够在消费级GPU上流畅运行的模型，称为小型视觉语言模型。 ... 在实际生产环境中部署视觉语言模型时，必须对其输入和 ...","doc_type":"web_page","link":"https://zhuanlan.zhihu.com/p/1905644587445359196","title":"视觉语言模型（更好、更快、更强） --2025"},{"content":"当我们谈论小型视觉语言模型时，我们通常指的是参数少于20 亿的模型，这些模型可以在消费级GPU 上运行。SmolVLM 是小型视觉语言模型家族的一个很好例子。","doc_type":"web_page","link":"https://huggingface.co/blog/zh/vlms-2025","title":"视觉语言模型(更好、更快、更强)"},{"content":"借助NVIDIA ChatRTX 等边缘部署技术，小型语言模型（SLM）可在消费级GPU 上实现本地运行，兼顾隐私保护与低延迟推理。这不仅有助于降低成本，更关乎可 ...","doc_type":"web_page","link":"https://developer.nvidia.com/zh-cn/blog/how-small-language-models-are-key-to-scalable-agentic-ai/","title":"小型语言模型如何成为可扩展代理人工智能的关键"},{"content":"论文提出了从大型模型向小型模型转换的算法，并通过案例研究证明在实际智能代理中40-70%的LLM调用可被SLM替代。这一转变将大幅降低AI运营成本，推动更可持续 ...","doc_type":"web_page","link":"https://www.techwalker.com/2025/0609/3167417.shtml","title":"小语言模型将成为AI智能代理的未来：NVIDIA研究团队揭示更 ..."},{"content":"视觉语言模型（如Qwen 2.5）的出现为解决这一困境提供了新思路。这类模型融合了视觉感知与自然语言理解能力，能够同时处理文本、图像、视频等多模态信息。","doc_type":"web_page","link":"https://blog.csdn.net/matt45m/article/details/150925259","title":"Qwen 2.5 视觉语言模型的零样本学习能力在多模态内容审核 ..."},{"content":"研究采用四阶段预训练与混合在线策略强化学习相结合的方法，处理了2.4万亿个标记。研究发现，预训练阶段纳入高质量推理数据至关重要，而混合强化学习虽提升 ...","doc_type":"web_page","link":"https://www.techwalker.com/2025/0707/3168616.shtml","title":"小米发布MiMo-VL-7B：一款令人惊艳的开源视觉语言模型"},{"content":"最新研究案例. 一篇名为ROSS 的论文提出了一种附加的重构视觉监督方法，用于帮助在LLM 中保留视觉上下文信息。 3.2 多模态投影器. 多模态投影器通常处理 ...","doc_type":"web_page","link":"https://zhuanlan.zhihu.com/p/7827587018","title":"2024 年视觉语言模型（VLMs）"},{"content":"VLM 将计算机视觉与自然语言处理相结合，有助于将我们看到的内容与我们所说的内容联系起来。它们使机器能够理解和处理视觉和文本信息，从而实现更自然、更 ...","doc_type":"web_page","link":"https://developer.nvidia.com/zh-cn/blog/best-in-class-multimodal-rag-how-the-llama-3-2-nemo-retriever-embedding-model-boosts-pipeline-accuracy/","title":"出色的多模态RAG：Llama 3.2 NeMo 检索器嵌入模型如何 ..."},{"content":"SmolVLM 是一个紧凑的开放式多模态模型，可接受任意序列的图像和文本输入，从而生成文本输出。 SmolVLM 专为提高效率而设计，它可以回答有关图像的问题、 ...","doc_type":"web_page","link":"https://blog.csdn.net/weixin_41446370/article/details/144342517","title":"【抱脸社最新力作】SmolVLM-Instruct：State-of-the-Art级小型 ..."},{"content":"2023年12月Google推出Gemini多模態模型，一共三個版本，Ultra模型為最大，功能也最強大，用於高度複雜任務如客製化專屬協作夥伴，將提供給企業和開發者使用， ...","doc_type":"web_page","link":"https://www.moea.gov.tw/MNS/doit/industrytech/IndustryTech.aspx?menu_id=13545&it_id=533","title":"探索邊緣小語言模型(SLM)應用與前景"}],"多模态数据集 LLaVA-Instruct 性能指标":[{"content":"这个基准数据集被划分为训练、验证和测试三个部分，分别包含12,726个、4,241个和4,241个样本。 在提出的LLaVA-Instruct-158K数据集上训练，epoch数量为3，学习率2e-5， ...","doc_type":"web_page","link":"https://zhuanlan.zhihu.com/p/692398098","title":"LLaVA系列多模态大模型总结"},{"content":"基准测试：使用标准数据集进行性能评估，这些数据集通常包括多种类型的图像和文本对。 · 压力测试：在高负载条件下测试模型的表现，包括并发请求处理和长时间 ...","doc_type":"web_page","link":"https://blog.csdn.net/gitblog_02546/article/details/145034255","title":"深入解析LLaVA-v1.5-13B模型的性能评估与测试方法原创"},{"content":"参数一：学习率 ... 功能：学习率决定了模型在训练过程中参数更新的步长，是影响模型收敛速度和最终性能的关键因素。 取值范围：学习率通常设置在1e-5到1e-3之间 ...","doc_type":"web_page","link":"https://blog.csdn.net/gitblog_02566/article/details/144844648","title":"深入解读LLaVA模型的参数设置：优化你的多模态对话体验"},{"content":"需要指出的是，本文主要介绍相关模型的技术方案，训练技巧，至于如何构造训练、测试数据，以及训练时具体的数据配比，这里不做过多介绍，会直接贴出数据以及模型 ...","doc_type":"web_page","link":"https://zhuanlan.zhihu.com/p/1934322862388385543","title":"多模态大模型之LLAVA 系列"},{"content":"在本文中，我们旨在追踪并总结MLLM的最新进展。首先，我们介绍了MLLM的基本公式，并概述了与其相关的概念，包括架构、训练策略和数据，以及评估。然后，我们介绍 ...","doc_type":"web_page","link":"http://www.360doc.com/content/24/0624/23/3066843_1127060932.shtml","title":"多模态大型语言模型（MLLM）综述"},{"content":"我们提出了一个端到端模型，简称LLaVA-Grounding(简称LLaVA-G)，它将LMM与定位模型连接起来，以促进定位视觉聊天。我们的模型支持目标级和像素级定位，可以 ...","doc_type":"web_page","link":"https://www.cnblogs.com/lucifer1997/p/18206255","title":"LLaVA-Grounding: Grounded Visual Chat with Large ..."},{"content":"核心是使用LLaVA-NeXT中同样的模型结构，把能力从图像拓展到视频中，其中对视频帧的处理和针对video数据的SFT值得我们关注一下。 Highlights：. 视频处理方面，跟Instruct-BLIP ...","doc_type":"web_page","link":"https://developer.volcengine.com/articles/7407662374783713299","title":"多模态大模型: 盘点&Highlights part1.5——从LLaVA-NeXT ..."},{"content":"因此，作者提出了LLaVA-Read，一个利用双重视觉编码器以及视觉文本编码器的多模态大型语言模型。作者的模型在各项富含文本的图像理解任务中超越了现有的最 ...","doc_type":"web_page","link":"https://developer.volcengine.com/articles/7400349596427223066","title":"LLaVA-Read 在多模态任务中的高性能表现！"},{"content":"LLaVA首次尝试构建图文相关的instruction tuning数据集来将LLM拓展到多模态领域。具体来说，基于MSCOCO数据集，每张图有5个较简短的ground truth描述 ...","doc_type":"web_page","link":"https://hub.baai.ac.cn/view/26707","title":"综述｜如何利用LLM做多模态任务？"},{"content":"模型：基于LLaVA的方法，添加了时空池化模块应对视频（多帧）场景，将LLaVA从单图扩展为多图（动态长度），同时将LLaVA的Vicuna语言模型换为Stable-Vicuna模型。； ...","doc_type":"web_page","link":"https://www.cnblogs.com/chengnan113/p/17538956.html","title":"LLaMA模型指令微调字节跳动多模态视频大模型Valley 论文 ..."}]}