{"轻量级多模态模型 7B参数以下 2024进展":[{"content":"CEC2022单目标测试集包括了各种类型的问题，涵盖了线性和非线性、单模和多模态、可微和不可微等多种优化挑战，为算法性能的评估提供了全面的平台。 最新的单 ...","doc_type":"web_page","link":"https://blog.csdn.net/nal/article/details/149002052","title":"多模态AI系统效能评估方法与基准测试原创"},{"content":"性能测量方法：介绍了三种主要的评估方法：基于人类的评估、基于LLM/MLLM的评估以及基于脚本的评估。此外，还介绍了两大类评估指标和四种评估工具包。 未来 ...","doc_type":"web_page","link":"https://zhuanlan.zhihu.com/p/16815782175","title":"万字长文总结多模态大模型评估最新进展"},{"content":"静态性能测试：评估在固定输入、固定输出和固定并发下，模型的吞吐与首token延迟。该方式实现简单，能比较清楚的看出模型的性能和输入输出长度、以及并发的 ...","doc_type":"web_page","link":"https://support.huaweicloud.com/bestpractice-modelarts/modelarts_llm_infer_91007.html","title":"多模态模型推理性能测试 - 华为云"},{"content":"... 测试工具）所示，性能基准测试关注的是衡量模型本身的实际性能，例如吞吐量、延迟和token 级指标。此类测试有助于识别与模型效率、优化和配置相关的问题。","doc_type":"web_page","link":"https://zhuanlan.zhihu.com/p/1917933276158489730","title":"LLM 性能基准测试相关概念、指标和参数"},{"content":"相比之下，如NVIDIA GenAI-Perf 工具所示，性能基准测试关注的是衡量模型本身的实际性能，例如吞吐量、延迟和token 级指标。此类测试有助于识别与模型效率、 ...","doc_type":"web_page","link":"https://developer.nvidia.com/zh-cn/blog/llm-benchmarking-fundamental-concepts/","title":"LLM 基准测试：基本概念"},{"content":"除了传统的成功率（SR），只有在所有子任务都完成时才将任务标记为成功，作者还引入了三个指标，衡量Agent的性能和效率： ... 执行效率（EE）计算为CR/A ...","doc_type":"web_page","link":"https://hub.baai.ac.cn/view/39093","title":"跨平台多模态智能体基准测试来了！但全班第一只考了35.26分"},{"content":"本综述通过系统回顾211个评估MLLMs的基准测试，填补了这一空白，涵盖了理解、推理、生成和应用四个核心领域。我们提供了任务设计、评估指标和数据集构建的 ...","doc_type":"web_page","link":"https://blog.csdn.net/Python_cocola/article/details/144160491","title":"推理、生成、应用、趋势_多模态大模型能力评测基准全面综述"},{"content":"目前，各类图文大模型评测指标从不同角度对模型性能进行了综合评判，常见指标有准. 确率、F1 值、BLEU、IS指标、CLIP相似度、PSNR、SOA、CIDEr、mAP、IoU、 ...","doc_type":"web_page","link":"https://pdf.dfcfw.com/pdf/H3_AP202410121640274768_1.pdf","title":"『弈衡』多模态大模型评测体系白皮书"},{"content":"大模型基准测试（Benchmark）的目标是通过设计合理的测试任. 务和数据集来对模型的能力进行全面、量化的评估。大模型基准测试. 体系涵盖了大模型的测评指标、方法、数据集等 ...","doc_type":"web_page","link":"https://www.caict.ac.cn/kxyj/qwfb/ztbg/202407/P020240711534708580017.pdf","title":"大模型基准测试体系研究报告(2024 年)"},{"content":"模算效率的首次提出，将增强不同预训练模型、软件框架和硬件系统之间的可比性，促进模型与硬件的协同优化，推动AI计算系统的能效提升和技术创新： 提升可比性 ...","doc_type":"web_page","link":"https://cnmobile.prnasia.com/story/475361-1.shtml","title":"国际最新AI基准测试SPEC ML首提模算效率，填补大模型计算 ..."}],"arXiv CVPR ICML 最新论文检索":[{"content":"摘要：我们介绍了LLaVA-MoD，这是一个旨在高效训练小型多模态语言模型（s-MLLM）的创新框架，通过从大规模多模态语言模型（l-MLLM）中提取知识来实现。","doc_type":"web_page","link":"https://zhuanlan.zhihu.com/p/1908162624962668528","title":"LLaVA-MoD：基于MoE结构和知识蒸馏，训练轻量化多模态 ..."},{"content":"... 结构的高效密集LLM。Switch Transformers探索了将稀疏模型蒸馏为密集模型的技术，证明了密集模型在压缩稀疏MoE模型97%参数后仍能保留超过30%的性能。","doc_type":"web_page","link":"https://zhuanlan.zhihu.com/p/18788701543","title":"专家混合模型（MOE）推理优化技术全景：从模型到硬件的深度 ..."},{"content":"本文提出了LLaVA-MoD，用于通过知识蒸馏从l-MLLM中高效训练s-MLLM。 该框架解决了MLLM蒸馏的两个关键挑战：使用MoE设计增强s-MLLM架构的效率和表达 ...","doc_type":"web_page","link":"https://blog.csdn.net/m0_59164520/article/details/148316109","title":"ICLR 2025 | LLaVA-MoD：MoE蒸馏训练轻量化多模态大模型"},{"content":"本文从LLM 架构角度出发，带你剖析大模型的效率秘诀。这一切的核心在于Transformer 架构。 Transformer 的自注意力机制虽带来了远距离建模的 ...","doc_type":"web_page","link":"https://blog.csdn.net/c9Yv2cf9I06K2A9E/article/details/150944918","title":"从Flash到MoE，大模型高效架构全景解析"},{"content":"MoE 模型通常比Dense 模型更大，但通过蒸馏技术可以将MoE 模型压缩为较小的Dense 模型，从而在保持性能的同时减少计算量。详细请参考《DeepSeek-R1 ...","doc_type":"web_page","link":"https://www.theriseunion.com/zh/blog/DeepSeek-MoE.html","title":"DeepSeek-V3 和Qwen2.5-Max 为什么选择MoE 作为核心架构？"},{"content":"摘要: 本文对大型语言模型（LLMs）高效架构进行了系统性调查，重点分析了传统Transformer架构的局限性及其在大规模训练和实际部署中的挑战。研究涵盖了线性和稀疏序列建模方法 ...","doc_type":"web_page","link":"https://github.com/pprp/Awesome-Efficient-MoE","title":"pprp/Awesome-Efficient-MoE"},{"content":"论文里并没有对MOE 的所有底层实现细节进行过多篇幅展开，但可以肯定的是，DeepSeek R1 选择MOE，主要是看中在数理推理的负载下能充分利用局部专家进行高效 ...","doc_type":"web_page","link":"https://www.ele-yufo.com/archives/2024","title":"从MoE 架构、原生CoT，到大规模强化学习与蒸馏 - ELE-yufo"},{"content":"我们引入了LLaVA-MoD，这是一个用于构建高效s-MLLM的新框架，该框架结合了专家混合（MoE）和知识蒸馏。我们的框架由两个主要组成部分组成：（a）s-MLLM的架构设计 ...","doc_type":"web_page","link":"http://m.zhiding.cn/article/3160970.htm","title":"阿里提出LLaVA-MoD架构！利用MOE技术让小模型也能 ..."},{"content":"DeepSeek-V3 採用混合專家（Mixture-of-Experts, MoE）架構，總參數達6710 億，但每次推理僅激活370 億參數。這種設計使其在保持模型容量的同時，將訓練成本 ...","doc_type":"web_page","link":"https://tenten.co/learning/deepseek-impact-to-ai/","title":"DeepSeek：開源模型與蒸餾技術驅動的AI 革命"},{"content":"DeepSeek的核心论文主要围绕强化学习驱动的推理优化（R1系列）和高效架构设计（V3系列）展开。通过算法创新（如GRPO、MTP）和工程优化（如FP8训练、蒸馏技术）， ...","doc_type":"web_page","link":"http://www.enginetech.cn/article/1028.html","title":"DeepSeek V3和R1系统架构之道：逆向渐进式创新出圈"}],"Hugging Face Model Zoo 模型库查询":[{"content":"本文总结了MLLM的最新进展，包括其基本架构、训练策略、数据和评估方法，并探讨了如何扩展MLLM以支持更细粒度的输入输出、更多模态、语言和应用场景。此外，还讨论了多模态 ...","doc_type":"web_page","link":"https://zhuanlan.zhihu.com/p/15363248761","title":"2024多模态大模型综述 - 知乎专栏"},{"content":"基于baichuan-7b的多模态大语言模型局限性受限于较小的参数量，羽人-百川7B 在数值计算、逻辑推理类任务的效果不尽人意，同时在多模态任务上也无法完全发挥 ...","doc_type":"web_page","link":"https://blog.csdn.net/m0_71745484/article/details/141015238","title":"2024年多模态大语言模型最新进展 - CSDN博客"},{"content":"MiniCPM-o 2.6是一个80亿参数的多模态模型，能够理解和生成视觉、语音和语言模态的内容。由DeepSeek AI推出的Janus-Pro-7B是一个统一的多模态模型，在 ...","doc_type":"web_page","link":"https://huggingface.co/blog/VirtualOasis/vlms-2025-zh-translation","title":"视觉语言模型（更好、更快、更强） - Hugging Face"},{"content":"第一阶段从冻结的图像编码器中引导视觉-语言表示学习。 第二阶段从冻结的LLM中引导视觉到语言的生成学习，这使得零样本指导的图像到文本生成成为可能。","doc_type":"web_page","link":"https://zhuanlan.zhihu.com/p/688215018","title":"万字长文总结多模态大模型最新进展（Modality Bridging篇）"},{"content":"Llama 3.2 系列模型涵盖了不同规模，最小的是1B 和3B 参数的轻量级纯文本模型，适合边缘设备使用，而11B 和90B 参数的中小型模型则能够执行包括高分辨率图像 ...","doc_type":"web_page","link":"https://aws.amazon.com/cn/blogs/china/introducing-llama-3-2-models-from-meta-in-amazon-bedrock-a-new-generation-of-multimodal-vision-and-lightweight-models/","title":"Amazon Bedrock 推出Meta 的Llama 3.2 模型：新一代多模态视觉和 ..."},{"content":"InternLM2 包含两种模型规格：7B 和20B。7B 为轻量级的研究和应用提供了一个轻便但性能不俗的模型，20B 模型的综合性能更为强劲，可以 ...","doc_type":"web_page","link":"https://github.com/HqWu-HITCS/Awesome-Chinese-LLM","title":"HqWu-HITCS/Awesome-Chinese-LLM: 整理开源的中文大语言模型 ..."},{"content":"高效轻量级LLM | Imp模型，通过低比特量化分辨率和降低实现高通骁龙8Gen3 芯片高性能部署！ ... 通过利用大型语言模型（LLM）的能力，最近的大规模多模态模型（ ...","doc_type":"web_page","link":"https://developer.volcengine.com/articles/7382344529577246770","title":"高效轻量级LLM | Imp模型，通过低比特量化分辨率和降低实现高通骁 ..."},{"content":"近年来，多模态AI 模型（能同时处理文本和图像的模型）取得了显著进展。商业模型如GPT-4o、Claude3.5 的多模态能力已经相当强大，可以直接用于图片分类任务。","doc_type":"web_page","link":"https://aws.amazon.com/cn/blogs/china/multimodal-large-model-application-practice-part-one/","title":"多模态大模型应用实践（一）- 利用微调LLaVA 实现高效酒店图片分类"},{"content":"根據Gartner調查，在2023年生成式AI方案多模態應用僅佔1%，但預估至2027年約有40%生成式AI方案將為將多模態應用，能處理文字、圖像、聲音、影片等不同資料型 ...","doc_type":"web_page","link":"https://www.moea.gov.tw/MNS/doit/industrytech/IndustryTech.aspx?menu_id=13545&it_id=573","title":"多模態AI結合具身智慧發展趨勢"},{"content":"2024 年，美国机构共开发了40 个标志. 性的人工智能模型，而中国只有15 个，欧洲只有3 个。虽然美国在数量上保持领先，但中国的模型在质量上迅速缩小了差距：.","doc_type":"web_page","link":"https://hai.stanford.edu/assets/files/hai_ai_index_report_2025_chinese_version_061325.pdf","title":"[PDF] 介绍2025年人工智能指数报告 - Stanford HAI"}],"多模态基准测试 计算效率 性能指标":[{"content":"arXiv是一个在线预印本存储库，涵盖了各种科学和技术领域的论文。我们的任务是根据论文之间的引用关系和元数据预测每篇论文的科目。 首先，让我们详细了解 ...","doc_type":"web_page","link":"https://blog.csdn.net/m0_59082437/article/details/145570144","title":"一款用于综合性学术论文检索的大语言模型智能体"},{"content":"2023年的顶会AAAI的论文列表还未公布，但通过在arxiv搜索“AAAI2023”就能找到一些AAAI已录用的论文。 ... 2023年顶会accepted papers list(NeurIPS/CVPR/ICML/ ...","doc_type":"web_page","link":"https://blog.csdn.net/weixin_43594279/article/details/131142455","title":"AI人工智能之科研论文搜索集锦原创"},{"content":"2020年arXiv十大热门论文来了！ ... 机器学习自然语言处理：排序(rank)后重排(re-rank)? · 赛尔笔记| 对比学习简述- 知乎(zhihu.com) · 20篇「ICML2021」最新论文抢先看！","doc_type":"web_page","link":"https://zhuanlan.zhihu.com/p/386931156","title":"每日论文速递：自然语言处理相关（7月5日更新版）"},{"content":"我个人觉得，不管论文什么时候发表的，都应该上传到arXiv 上。在那上面获取论文通常比各种会议论文集方便多了，有些会议论文集很难搜索，或者需要付费才能看。","doc_type":"web_page","link":"https://www.reddit.com/r/MachineLearning/comments/5twnhv/d_how_early_is_too_early_to_put_work_on_arxiv/?tl=zh-hans","title":"[D] 论文发到ArXiv 上，多早算太早？ : r/MachineLearning"},{"content":"2020年arXiv十大热门论文来了！不止GPT-3、SimCLR、YOLOv4... 每日论文速递 ... 20篇「ICML2021」最新论文抢先看！看机器学习2021在研究什么？ - 知乎(zhihu.com).","doc_type":"web_page","link":"https://zhuanlan.zhihu.com/p/390113891","title":"每日论文速递：计算机视觉相关（7月15日更新版）"},{"content":"Arxiv 拥有庞大的学术用户群，论文一旦上传，就可以被全球的研究者搜索、阅读和引用。 许多研究人员习惯直接从arxiv 获取最新的研究动态，而不必等正式出版。 高质量的 ...","doc_type":"web_page","link":"https://ghrnet.org/viewer/arxiv-latex-template.html","title":"Arxiv Latex Template | Ghrnet At Templates"},{"content":"经过四个多月的累积，Cool Papers收录的Arxiv论文数到了8万多篇，加上venue分支的会议论文也达到了8万多，目前近17万篇论文，可以拿来搜一搜了。","doc_type":"web_page","link":"https://www.spaces.ac.cn/archives/10088/comment-page-1","title":"Cool Papers更新：简单搭建了一个站内检索系统"},{"content":"如果你非常确定自己想要找什么，比如知道论文的名字（算法的名字）或者作者的名字，直接去Google Scholar上搜索是最快的。然而如果你并不是很确定自己想要 ...","doc_type":"web_page","link":"https://cloud.tencent.com/developer/article/1099479","title":"免费知识哪里来——Arxiv使用指南"},{"content":"目前，HyperAI超神经已经解读分享了近200 篇论文，为了便于大家检索，我们将文章根据学科进行分类，并展示了发表期刊及时间，提取了关键词（研究团队、相关研究、数据集等），大家 ...","doc_type":"web_page","link":"https://github.com/hyperai/awesome-ai4s","title":"Awesome AI for Science"},{"content":"高质量期刊会议：CVPR、ECCV、ICCV、AAAI、NIPS、ICLR、ICML等. 知名团队 ... arXiv（预印本平台，推荐），顶会直接搜索论文. （2）分类较为齐全的 ...","doc_type":"web_page","link":"https://www.cnblogs.com/Anthony7/p/13976012.html","title":"顶级论文索引网站- Anthony7"}],"VLM 高效架构 MoE设计 蒸馏技术":[{"content":"Models ; tencent/Hunyuan-MT-7B · 3.85k · 499 ; microsoft/VibeVoice-1.5B · 218k · 1.5k ; tencent/HunyuanWorld-Voyager · 496 · 453 ; meituan-longcat/LongCat-Flash-Chat.","doc_type":"web_page","link":"https://huggingface.co/models","title":"Models - Hugging Face"},{"content":"... 模型库（OpenDILab Hugging Face Model Zoo）：. 1. 引言：为什么决策AI 社区需要Model Zoo. 1、公共知识资源库(Public resources). 近两三年来，在人工 ...","doc_type":"web_page","link":"https://zhuanlan.zhihu.com/p/654919693","title":"OpenDILab 实践指南（2）：Hugging Face Model Zoo - 知乎专栏"},{"content":"一：如何找到统一使用方法 · 1. 先在模型下面找到你需要的模型点开 · 2. 点开最右边的Use in Transformers ...","doc_type":"web_page","link":"https://blog.csdn.net/qq_41458274/article/details/131175991","title":"huggingface 中模型如何查找和使用？ 原创 - CSDN博客"},{"content":"STM32 AI Model Zoo是一个预训练机器学习模型的集合，这些模型经过优化，可在STM32微控制器上运行。可从GitHub获取，如果想要为基于STM32的项目增加AI功能，可以利用这一宝贵 ...","doc_type":"web_page","link":"https://stm32ai.st.com/zh/model-zoo/","title":"STM32 Model Zoo - STMicroelectronics"},{"content":"HuggingFace查询、下载数据步骤 · 1. 安装必要的库. 安装 huggingface_hub 库，用于与Hugging Face Hub 交互： · 2. 登录Hugging Face 账户. 如果需要下载 ...","doc_type":"web_page","link":"https://blog.csdn.net/qq_38308388/article/details/147147386","title":"【HuggingFace】查找、下载数据和模型（小白都能会） - CSDN博客"},{"content":"Missing: Zoo 查询","doc_type":"web_page","link":"https://huggingface.co/docs/transformers/zh/main_classes/model","title":"模型 - Hugging Face"},{"content":"在这一章中，我会介绍现阶段模型常见的下载和使用方式，并推荐一些当下使用较为频繁、口碑好的模型， 最后会介绍炼制各种模型的方法 （鸽了）。","doc_type":"web_page","link":"https://huggingface.co/JasonWen/AI_furry_encyclopedia/blob/1ee375b571a45c8ae9908c6c338ab2d723148236/Models%E6%A8%A1%E5%9E%8B%E7%B1%BB%E5%9E%8B%E4%B8%8E%E6%8E%A8%E8%8D%90.md","title":"Models模型类型与推荐.md - Hugging Face"},{"content":"首先我们导入依赖项并从onnx模型库中下载并加载efficientnet-lite4模型。然后从labels_map.txt文件中加载标签。接着我们设置预处理函数，加载模型进行推理，并设置推理函数。","doc_type":"web_page","link":"https://www.aidoczh.com/gradio/guides/Gradio-and-ONNX-on-Hugging-Face.html","title":"Gradio And ONNX On Hugging Face - AiDocZh"},{"content":"LLaVA is a novel end-to-end trained large multimodal model that combines a vision encoder and Vicuna for general-purpose visual and language understanding.","doc_type":"web_page","link":"https://ollama.com/library","title":"library - Ollama"},{"content":"No information is available for this page. · Learn why","doc_type":"web_page","link":"https://github.com/rebellions-sw/rbln-model-zoo/tree/main/huggingface","title":"huggingface - GitHub"}]}