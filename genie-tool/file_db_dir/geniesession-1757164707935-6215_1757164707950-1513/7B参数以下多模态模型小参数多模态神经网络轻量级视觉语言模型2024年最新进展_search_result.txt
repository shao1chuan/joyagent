{"轻量级视觉语言模型 7B参数 架构创新":[{"content":"提出了迭代交互机制，通过在块状多模态变换器之间共享参数来减少模型复杂性和计算成本。这种迭代学习策略在不增加可学习参数的情况下，进一步改善了模型性能 ...","doc_type":"web_page","link":"https://zhuanlan.zhihu.com/p/680787323","title":"顶会热点！交叉注意力融合2024创新方案汇总，附配套模块 ..."},{"content":"文中探索了最新进展，并将SOTA 融合方法分为五类：编码器-解码器方法、注意力机制方法、GNN 方法、GenNN 方法和其他基于约束的方法，如图5所示。","doc_type":"web_page","link":"https://zhuanlan.zhihu.com/p/942563588","title":"学术最前沿！2024最新深度多模态数据融合综述来袭！"},{"content":"多模态融合搜索空间：定义了一个新的通用搜索空间，涵盖了大量可能的融合架构，考虑了从所有隐藏层提取的特征。 · 顺序模型基础优化（SMBO）：采用SMBO方案，通过 ...","doc_type":"web_page","link":"https://blog.csdn.net/d22800/article/details/145920884","title":"多模态融合全新创新思路！2024顶会论文汇总！ 原创"},{"content":"当前研究正致力于解决其计算效率、局部与全局信息平衡、多模态融合等挑战，推动注意力机制向更轻量、更具泛化能力的方向发展。理解其内在逻辑，有助于把握 ...","doc_type":"web_page","link":"https://blog.csdn.net/Mikasa33/article/details/148398706","title":"顶会最爱的注意力机制，我整理了2025最新魔改方案"},{"content":"多模态融合技术的探索： 开始探索如何将视觉编码器与语言模型相结合，以实现跨模态的信息融合；. 出现了多种融合策略，包括直接连接、交叉注意力机制和联合 ...","doc_type":"web_page","link":"https://developer.volcengine.com/articles/7389112087835836466","title":"2024年全面的多模态大模型5000字分析总结（122个MLLMs）"},{"content":"... 进展。 OpenAI 提出了一种基于注意力机制的全新跨模态特征融合架构——MultiAttenNet。该架构通过构建多层级的注意力模块，能够动态地对不同模态数据的特征进行加权融合。","doc_type":"web_page","link":"https://open.alipay.com/portal/forum/post/200801123","title":"我“AI”发文-- 2024 AI 多模态发展回顾—— 顶尖机构视角"},{"content":"厦门大学多媒体可信感知与高效计算教育部重点实验室NeurIPS 2024接收了14篇论文，涵盖多模态大模型、三维视觉、行人重识别、多智能体强化学习、联邦 ...","doc_type":"web_page","link":"https://informatics.xmu.edu.cn/info/1053/41639.htm","title":"多媒体可信感知与高效计算教育部重点实验室14篇论文被 ..."},{"content":"多模态融合的优点在于：① 来自不同模态的数据具有不同的预测能力，利用多模态数据间的互补性提高模型性能；② 不仅能利用多模态数据各自的信息，还能捕捉多模态数据间的交互信息 ...","doc_type":"web_page","link":"https://pmc.ncbi.nlm.nih.gov/articles/PMC11527755/","title":"基于深度学习的电子病历多模态数据融合研究进展"},{"content":"2024年是多模态大模型的爆发年，Meta、DeepMind等机构的研究揭示了跨模态推理的巨大潜力与现存挑战。从模态融合到对齐技术，从数据偏差到因果推理，每一项突破都让AI更接近 ...","doc_type":"web_page","link":"https://open.alipay.com/portal/forum/post/203901020","title":"多模态大模型爆发年：Meta、DeepMind学者揭秘跨模态推理 ..."},{"content":"在128K 超长序列上下文建模任务中，CCA-Attention 的推理速度是标准自注意力机制的7.9 倍，同时键值缓存（KV Cache）显存占用减少93%，性能全面优于现有高效 ...","doc_type":"web_page","link":"https://www.51cto.com/article/817694.html","title":"CCA-Attention为LLM长文本建模带来突破性进展"}],"MMBench VQAv2 性能基准 最新指标":[{"content":"第一阶段平衡各类数据；第二阶段大幅增加数学和代码数据的比例至约70%；第三阶段引入10%的合成推理数据并扩展上下文长度至32,768 个token。 最终，模型在约25 ...","doc_type":"web_page","link":"https://m.ofweek.com/ai/2025-05/ART-201700-8220-30662293.html","title":"小米开源首个7B推理AI大模型！聊聊小米如何通过架构创新和奖励 ..."},{"content":"该项目不仅公开了完整的模型权重、训练代码和训练数据集，也延续了原有的模块化设计架构，研究人员可根据具体实验需求，灵活替换语言模型、视觉编码器等核心 ...","doc_type":"web_page","link":"https://zhuanlan.zhihu.com/p/22742742121","title":"北航推出TinyLLaVA-Video，有限计算资源优于部分7B模型，代码"},{"content":"仅有7B参数的MiMo-VL-7B-RL在40项评测中的35项上超越Qwen2.5-VL-7B，在OlympiadBench上达到59.4分，超越了参数量达78B的模型。研究采用四阶段预训练与 ...","doc_type":"web_page","link":"https://www.techwalker.com/2025/0707/3168616.shtml","title":"小米发布MiMo-VL-7B：一款令人惊艳的开源视觉语言模型 - 科技行者"},{"content":"近期，研究人员提出了一个突破性的框架Eve（Efficient Vision Language Models with Elastic Visual Experts），仅用1.8B的参数量就实现了超越7B规模LLaVA-1.5 ...","doc_type":"web_page","link":"https://zhuanlan.zhihu.com/p/17933132853","title":"让AI真正看懂图像| 1.8B参数完胜7B！Eve模型刷新小型多模态AI新 ..."},{"content":"DeepSeek Janus-Pro-7B AI模型是一个创新的多模态人工智能模型，它的推出预示着人工智能领域的一大进步。这款AI图像生成器不仅融合了图像理解与文本到图像 ...","doc_type":"web_page","link":"https://blog.csdn.net/weixin_60180674/article/details/148305067","title":"AI大模型7B级别对比：性能、效率与应用场景分析原创 - CSDN博客"},{"content":"... 轻量级视觉语言模型，通过技术创新和数据优化，在7B 参数规模下实现了优异的多语言理解和实际应用能力」 核心创新： - 视觉能力升级：采用NaViT 视觉 ...","doc_type":"web_page","link":"https://x.com/shao__meng/status/1867100542746628217","title":"meng shao on X: \"POINTS1.5：高效视觉语言模型的实用化探索 ..."},{"content":"新标杆：首个开源的7B参数级视觉-语言融合模型. 技术突破：在VQAv2基准达到82.1%准确率（接近GPT-4V 85.3%）. 部署优势：8G显存即可运行，支持消费级显卡推理 ...","doc_type":"web_page","link":"https://blog.csdn.net/weixin_58022259/article/details/145441215","title":"人人可用的视觉理解引擎——DeepSeek Janus-Pro-7B多模态模型 ..."},{"content":"当前主流的开源视觉语言模型通常表现出色，这通常依赖于背后不少于7B参数的语言模型组件。 ... 1）一个视觉编码器，2）一个轻量级语言模型（LLM），以及3）一个负责 ...","doc_type":"web_page","link":"https://developer.volcengine.com/articles/7389113320026374198","title":"Xmodel-VLM | 多模态视觉语言模型，解决高成本难题，实现高效部署！"},{"content":"本报告聚焦于视觉语言大模型在复杂数字界面场景中的应用挑战，探索数字界面感知与交互智能体的构建方法，并提供一种模型小型化的实践方案。该场景下数据规模 ...","doc_type":"web_page","link":"https://ccig.csig.org.cn/2025/6888/list.html","title":"大模型复杂场景理解与轻量化应用论坛 - 中国图象图形大会"},{"content":"轻量级强力模型 ... 研究人员过去通过增加参数数量，然后是利用高质量的合成数据来提升模型智能。在某个节点后，基准测试开始饱和，扩展模型的收益递减。研究界 ...","doc_type":"web_page","link":"https://huggingface.co/blog/zh/vlms-2025","title":"视觉语言模型(更好、更快、更强) - Hugging Face"}],"Small Language Model 视觉语言 研究空白":[{"content":"综上所述，GUIRepair是一个极具价值的研究成果，它不仅填补了当前自动程序修复领域中的空白，还提出了一个新的思路来整合视觉与文本信息，从而提高修复效果。","doc_type":"web_page","link":"https://zhuanlan.zhihu.com/p/1920431670714163668","title":"论文分享| 多模态大模型最新进展"},{"content":"摘要： 这本多模态大型语言模型（MLLMs）调查与应用指南探讨了快速发展的MLLMs 领域，研究了它们的架构、应用以及对人工智能和生成模型的影响。从基础概念开始 ...","doc_type":"web_page","link":"https://blog.csdn.net/weixin_44362044/article/details/147879012","title":"AI推介-多模态视觉语言模型VLMs论文速览（arXiv方向）"},{"content":"尽管当前的VLM在多种任务上表现出色，但它们并未专门针对视觉检查任务进行训练，因此该模型通过设计特定的数据集和方法，填补了这一空白。 核心方法论. 数据 ...","doc_type":"web_page","link":"https://www.themoonlight.io/zh/review/vision-language-in-context-learning-driven-few-shot-visual-inspection-model","title":"[论文审查] Vision-Language In-Context Learning Driven ..."},{"content":"总的来说，这篇论文为跨语言多模态学习的研究提供了一个重要的参考案例，展示了如何利用大规模的数据集来评估和比较不同领域的视觉-语言模型。 SCAM: A Real ...","doc_type":"web_page","link":"https://zhuanlan.zhihu.com/p/1895092644725629573","title":"论文分享| 多模态大模型最新进展"},{"content":"小型語言模型（small language model，SLM）比起大型語言模型可望提供更低成本、更具效率的處理能力，未來適用於筆電和手機等裝置。英特爾日前宣布 ...","doc_type":"web_page","link":"https://vocus.cc/article/6869ff79fd89780001146ed0","title":"而是更「小」？NVIDIA 論文研究SLM 的三大革命性優勢"},{"content":"最近的研究表明，使用网络规模数据训练的大型语言模型（LLMs）和视觉语言模型（VLMs）能够增强端到端自动驾驶系统，从而实现更好的泛化和解释。具体而言，通过将输入动态路由到 ...","doc_type":"web_page","link":"https://github.com/chenin-wang/awesome_ai_paper","title":"chenin-wang/awesome_ai_paper"},{"content":"在这篇文章中，我们提出了一个全面的调查SLM，专注于他们的架构，训练技术和模型压缩技术。我们提出了一种新的分类法，用于分类的方法来优化SLM，包括模型压缩， ...","doc_type":"web_page","link":"https://blog.csdn.net/qq_29868553/article/details/144317029","title":"小语言模型综述（A Survey of Small Language Models）"},{"content":"因此本文提出了一個簡化的VLP模型，Vision-and-Language Transformer（ViLT），這個模型在處理視覺輸入時僅使用與處理文本輸入相同的無卷積方法。在研究顯示中 ...","doc_type":"web_page","link":"https://tomohiroliu22.medium.com/66%E5%80%8B%E8%A6%96%E8%A6%BA%E8%AA%9E%E8%A8%80%E6%A8%A1%E5%9E%8Bvlm%E7%B6%93%E5%85%B8%E8%AB%96%E6%96%87-f44f280a7f62","title":"66個視覺語言模型VLM經典論文 - 劉智皓(Chih-Hao Liu)"},{"content":"6. SLM — 小型语言模型（Small Language Model）. 图片. 虽然LLM凭借其庞大的规模占据了聚光灯，但小型语言模型（SLM）却在幕后默默地工作。它们存在于 ...","doc_type":"web_page","link":"https://www.51cto.com/aigc/6072.html","title":"2025年必备的八种AI模型：别再把所有AI都叫LLM了！"},{"content":"论文“小视觉语言模型：紧凑架构和技术综述”深入探讨了小型视觉语言模型（sVLMs）的发展，特别是在多模态人工智能领域的应用。sVLMs的出现标志着在资源受限 ...","doc_type":"web_page","link":"https://www.themoonlight.io/zh/review/small-vision-language-models-a-survey-on-compact-architectures-and-techniques","title":"[论文审查] Small Vision-Language Models: A Survey on ..."}],"高效注意力机制 模态融合策略 2024年进展":[{"content":"像VQAv2 或COCO 标题这样的传统基准提供了定量的性能测量，但缺乏细粒度的能力评估和非稳健的评估指标。最近的主观基准，如OwlEval，通过结合人力提供了对模型能力的 ...","doc_type":"web_page","link":"https://zhuanlan.zhihu.com/p/694361831","title":"多模态大模型评估基准 - 知乎专栏"},{"content":"传统基准如VQAv2和COCO Caption提供了定量性能测量，但在细粒度能力和鲁棒性评估指标方面存在不足。而像OwlEval这样的主观性基准虽然能够全面评价模型 ...","doc_type":"web_page","link":"https://blog.csdn.net/OpenCompass/article/details/140955749","title":"多模态模型评测神器| OpenCompass MMBench 了解一下！-CSDN博客"},{"content":"现有的基准仍可以仅凭单帧图像以获取较高的分数，说明问题和画面的时序性关联不强； 对开放性问题的评估仍旧采用较旧的GPT-3.5，打分和人类偏好有较大的偏差 ...","doc_type":"web_page","link":"https://blog.csdn.net/OpenCompass/article/details/144668037","title":"全面评估多模态大模型视频理解能力_mmbench-video-CSDN博客"},{"content":"该基准整合了28 个现有数学多模态数据集和3 个新构建数据集（IQ 测试、函数问答、论文问答），共计6,141 个样本，要求模型具备细粒度视觉理解与组合式推理能力。通过对12 个 ...","doc_type":"web_page","link":"https://zhuanlan.zhihu.com/p/31375584664","title":"MLLM/vLLM 常用Benchmark总结 - 知乎专栏"},{"content":"苹果大模型MM1杀入场：300亿参数、多模态、MoE架构，超半数作者是华人 · 数据经验1：交错数据有助于提高少样本和纯文本性能，而字幕数据则能提高零样本性能。 · 数据经验2： ...","doc_type":"web_page","link":"https://finance.sina.com.cn/tech/roll/2024-03-15/doc-inankpnu6887107.shtml","title":"苹果大模型MM1杀入场：300亿参数、多模态、MoE架构，超半数 ..."},{"content":"该论文主要围绕MM1模型展开实验，通过精心设计的对照实验，深入探讨了影响模型效果的各种关键因素。研究结果显示，图像分辨率和图像标注数量对模型性能具有显著影响，而 ...","doc_type":"web_page","link":"https://www.sohu.com/a/765034393_121850782","title":"苹果发布300亿参数MM1模型，图像与自然语言处理再获突破_研究_ ..."}],"MoE-LLaVA 代表性模型 技术特点":[{"content":"MoE-LLaVA代表了大型视觉语言模型(LVLMs)发展的重大飞跃。 通过集成混合专家方法，解决了传统LVLMs固有的计算效率低下和缩放困难的核心挑战。 MoE-LLaVA的 ...","doc_type":"web_page","link":"https://blog.csdn.net/deephub/article/details/136065867","title":"MoE-LLaVA:具有高效缩放和多模态专业知识的大型视觉语言模型原创"},{"content":"MoE-LLaVA:具有高效缩放和多模态专业知识的大型视觉语言模型. MoE-LLaVA代表了大型视觉语言模型(LVLMs)发展的重大飞跃。通过集成混合专家方法，解决了 ...","doc_type":"web_page","link":"https://blog.csdn.net/moxibingdao/article/details/135984924","title":"MoE-LLaVA——将多模态大模型稀疏化转载 - CSDN博客"},{"content":"MoE-LLaVA采用了混合专家(Mixture of Experts)架构，这种设计允许模型在处理不同任务时动态激活特定的专家模块。相比传统的大语言模型，MoE架构能够在不显著 ...","doc_type":"web_page","link":"https://blog.gitcode.com/b09a0f4359a93db8ccef1577ed501469.html","title":"MoE-LLaVA项目本地复现指南：从Huggingface Spaces到本地部署"},{"content":"在众多基准测试中，MoE-LLaVA模型展现出了其卓越的视觉理解能力，尤其是在减少对象幻觉方面的表现尤为突出。这些成果不仅证明了MoE-LLaVA在技术上的先进性， ...","doc_type":"web_page","link":"https://zhuanlan.zhihu.com/p/683221608","title":"MoE-LLaVA: 实现高性能与低成本的多模态AI革新 - 知乎专栏"},{"content":"，MoE-LLaVA 在各种视觉理解数据集上表现出与LLaVA-1.5-7B 相当的性能，甚至在物体幻觉基准测试中超越了LLaVA-1.5-13B。","doc_type":"web_page","link":"https://sth.ai/article/MoELLaVA","title":"MoE-LLaVA：大型视觉语言模型的专家混合体| 𝖲𝗈𝗆𝖾𝗍𝗁𝗂𝗇𝗀AI"},{"content":"MoE-LLaVA利用了“专家混合”策略融合视觉和语言数据，实现对多媒体内容的复杂理解和交互。为增强LVLMs提供了更高效、更有效的解决方案，而不受传统缩放方法的 ...","doc_type":"web_page","link":"https://www.cnblogs.com/deephub/p/18010723","title":"MoE-LLaVA:具有高效缩放和多模态专业知识的大型视觉语言模型"},{"content":"这篇论文提出了一个名为MoE-LLaVA 的新型视觉-语言模型（LVLM），它基于混合专家（Mixture of Experts, MoE）架构，旨在解决现有LVLM 在扩展模型规模时面临的计算成本问题。现有 ...","doc_type":"web_page","link":"https://www.themoonlight.io/zh/review/moe-llava-mixture-of-experts-for-large-vision-language-models","title":"[论文审查] MoE-LLaVA: Mixture of Experts for Large Vision ..."},{"content":"由于MoE模型的规模庞大，直接部署具有挑战性。因此，知识蒸馏提供了一种潜在的解决方案，可以从原始MoE模型生成紧凑的高性能模型。例如，LLaVA-MoD ...","doc_type":"web_page","link":"https://zhuanlan.zhihu.com/p/18788701543","title":"专家混合模型（MOE）推理优化技术全景：从模型到硬件的深度解析"},{"content":"从一张图表中，MoE-LLaVA可以精准分析之中的细节，连线条的颜色都能把控到位。 推理能力也十分优秀，能够根据照片场景针对性地给出旅行建议。 在物体幻觉基准 ...","doc_type":"web_page","link":"https://www.thepaper.cn/newsDetail_forward_26325912","title":"3B模型不输7B LLaVA，北大多模态MoE模型登GitHub热榜 - 澎湃新闻"}]}