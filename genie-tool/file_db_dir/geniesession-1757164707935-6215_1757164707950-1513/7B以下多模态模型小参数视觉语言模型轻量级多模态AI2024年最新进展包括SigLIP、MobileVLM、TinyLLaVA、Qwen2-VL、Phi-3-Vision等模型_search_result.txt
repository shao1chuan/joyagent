{"推理速度 能耗 2024年研究进展":[{"content":"分析BRAVE在预训练数据量、模型大小和可训练参数数量方面的效率。 与现有方法相比，展示BRAVE在保持较少可训练参数的同时如何实现更好的性能。","doc_type":"web_page","link":"https://zhuanlan.zhihu.com/p/691942949","title":"Arxiv 24.4.11 多模态/视觉语言模型Multi-Modal/Vision-Language Model"},{"content":"这种下降表明，内部融合中的模块化方法在参数效率方面可能存在问题，或者在整合更复杂的视觉编码器时容易出现过拟合。 最后总结下. 这里主要深入分析了多层 ...","doc_type":"web_page","link":"https://zhuanlan.zhihu.com/p/29580196582","title":"多模态大语言模型中如何有效完成多层视觉特征融合？指南来啦"},{"content":"(1) OpenVLA 通过结合强大的开源VLM backbone和更丰富的大规模机器人预训练数据，在实验中实现了优于RT-2-X 的性能，且参数量减少一个数量级； (2) ...","doc_type":"web_page","link":"https://blog.csdn.net/qq_45933056/article/details/150067162","title":"【论文精读】OpenVLA:一个开源的视觉-语言-动作模型 - CSDN博客"},{"content":"通过引入轻量化注意力机制、动态路由模块和自适应特征融合技术，该模型在保持9B参数规模的同时，实现了对复杂任务的精准响应。这种“以小见大”的设计哲学， ...","doc_type":"web_page","link":"https://www.yicaiai.com/news/article/6865e17b4ddd79013c003481","title":"小参数量大能量：解析中文视觉语言模型的新突破 - 易源易彩"},{"content":"亚利桑那州立大学团队开发出MMTok技术，通过多模态覆盖最大化方法，让视觉语言AI模型在保持98.7%准确度的同时实现1.87倍速度提升。","doc_type":"web_page","link":"http://m.zhiding.cn/article/3171188.htm","title":"多模态视觉语言模型的智能\"减肥术\"：亚利桑那州立大学团队让AI看图 ..."},{"content":"本报告旨在对当前主流的开源视觉大语言模型进行一次全面而深入的技术剖析。报告将以Qwen-VL系列为核心案例，系统性地对比分析LLaVA、CogVLM、InternVL等 ...","doc_type":"web_page","link":"https://blog.csdn.net/weixin_37763484/article/details/148903011","title":"【多模态大模型】原理介绍与细节分析原创 - CSDN博客"},{"content":"LLaMA-Adapter V2 ： 通过引入视觉专家，早期融合视觉知识，增加可学习参数等方式，改善了 LLaMA 的指令跟随能力，提高了在传统视觉-语言任务上的性能。 综上所 ...","doc_type":"web_page","link":"https://www.hfuu.edu.cn/CVPR/ce/98/c10439a118424/page.htm","title":"万字长文带你全面解读视觉大模型"},{"content":"视觉语言模型(VLM) 是一种人工智能(AI) 模型，其融合了计算机视觉和自然语言处理(NLP) 功能。 VLM 学习映射文本数据与图像或视频等视觉数据之间的关系， ...","doc_type":"web_page","link":"https://www.ibm.com/cn-zh/think/topics/vision-language-models","title":"什么是视觉语言模型(VLM)？ - IBM"},{"content":"我们的研究发现，后期融合架构并不比早期融合架构具有固有的优势，后者不依赖于图像编码器。相反，早期融合在参数数量较少的情况下表现出更强的性能，训练效率 ...","doc_type":"web_page","link":"https://swarma.org/?p=59632","title":"原生多模态模型的标度律：重新思考架构选择与训练效率 - 集智俱乐部"},{"content":"i-VL 是一款开源的视觉语言模型，采用混合专家（MoE）技术，具备强大的多模态推理能力。该模型能够处理长文本上下文，并展现出高效的代理功能。","doc_type":"web_page","link":"https://www.showapi.com/news/article/67f7bde24ddd79013c0020db","title":"开源视觉语言模型的革新：i-VL与混合专家技术揭秘 - 万维易源"}],"MMBench VQAv2 准确率 对比实验":[{"content":"定量结果 7B 和13B 开源多模态LLMs 的平均准确率徘徊在35–42%左右，这与随机猜测（38.09%）相似。 效果最好的开源模型LLaVA-v1.6-34B 达到了45.05%的准确率。","doc_type":"web_page","link":"https://zhuanlan.zhihu.com/p/694361831","title":"多模态大模型评估基准 - 知乎专栏"},{"content":"基于脚本的评估方法较为简单，通常用于基于多项选择或“是或否”问题的基准测试。这些评估根据预定义规则进行结果比较。这种方法评估速度快，但也最终准确性很 ...","doc_type":"web_page","link":"https://zhuanlan.zhihu.com/p/16815782175","title":"万字长文总结多模态大模型评估最新进展 - 知乎专栏"},{"content":"* 大多数医学专用模型难以达到通用LVLMs 的一般性能水平（约30% 的准确率），但MedDr 除外，其准确率达到43.69%。","doc_type":"web_page","link":"https://hub.baai.ac.cn/view/41177","title":"覆盖18项临床任务，上海AI Lab等发布多模态医疗基准GMAI-MMBench"},{"content":"MMBench 是OpenCompass 研究团队自建的视觉语言模型评测数据集，可实现从感知到认知能力逐级细分评估。研究团队从互联网公开信息与权威基准数据集采 ...","doc_type":"web_page","link":"https://blog.csdn.net/OpenCompass/article/details/140955749","title":"多模态模型评测神器| OpenCompass MMBench 了解一下！-CSDN博客"},{"content":"本研究工作分别在1/4、1/9、1/16 的视觉token 压缩比下，进行对比实验。在六种benchmark 下进行验证，包括综合理解：MMBench，MM-Vet；视觉问答：VizWiz，VQAv2， ...","doc_type":"web_page","link":"https://www.linkresearcher.com/theses/0035a5a4-2ef6-4ce5-8c29-c6ed0f8d5eb7","title":"蚂蚁等提出TokenPacker，多模态大模型中的高质量视觉token压缩方法"},{"content":"对开放性问题的评估仍旧采用较旧的GPT-3.5，打分和人类偏好有较大的偏差且并不准确，容易高估模型性能。 针对这些问题，有没有对应的基准能够较好解决这些 ...","doc_type":"web_page","link":"https://blog.csdn.net/OpenCompass/article/details/144668037","title":"全面评估多模态大模型视频理解能力_mmbench-video-CSDN博客"},{"content":"从结果中我们可以发现，现有对话模型在MVBench性能表现很不理想，最强的图像对话模型LLaVA和视频对话模型VideoChat，相比随机的27.7%准确率只高了不到9个点。","doc_type":"web_page","link":"https://www.cvmart.net/community/detail/8475","title":"[CVPR2024] MVBench多模态视频理解能力的全面评测-极市开发者社区"},{"content":"实验评估表明，ALTA在文本到图像的准确率方面比性能最佳的同类方法高出4%以上，在图像到文本的检索准确率方面高出约6%。在高效对齐过程中对图像-文本模型的自适应也 ...","doc_type":"web_page","link":"https://github.com/chenin-wang/awesome_ai_paper","title":"chenin-wang/awesome_ai_paper - GitHub"},{"content":"实验结果显示，VScan能够在几乎不降低准确率的前提下，有效减少视觉Token数量，显著缩短推理时间，展现出优于现有方法的综合性能。 具体而言，首先将 ...","doc_type":"web_page","link":"https://hub.baai.ac.cn/view/47057","title":"无损加速视觉语言模型推理！轻松剪掉视觉冗余Token｜腾讯AI Lab"}],"SigLIP MobileVLM 性能指标 评测数据集":[{"content":"◼ 由实验可见，Prefill与Decode阶段存在高达137×的速度差距，其中Decode流程耗. 时占总推理时间99%以上，表明单一的流水线不能充分发挥GPU并行算力；因此，. 将 ...","doc_type":"web_page","link":"https://pdf.dfcfw.com/pdf/H3_AP202507101706460530_1.pdf?1752177028000.pdf","title":"2025年中国AIDC产业发展白皮书： - 智算中心如何 ..."},{"content":"在2024年，多个新兴模型的能力显著提升，尤其是OpenAI的o1系列和Google的Gemini 2.0。这些模型在推理速度、API价格等方面均有显著改善，甚至在某些任务上超越 ...","doc_type":"web_page","link":"https://liuwei.blog/2025/01/29/2024ai%E8%BF%9B%E5%B1%95/","title":"2024AI进展"},{"content":"2024 年 AI 所需時間的增長速度加快，最新模型約每三個月翻倍一次。按照 2019-2024 年的進展速度，METR 預測 AI 模型可能會在 2029 年（甚至更早）達到能 ...","doc_type":"web_page","link":"https://concert.stpi.niar.org.tw/web.focus/detail/sn/465","title":"AI將能夠快速能完成人類需要耗時數週的工作"},{"content":"... 推理成本驟降，訓練能耗激增，AI Agent 也初露鋒芒。 報告指出，達到GPT-3.5 表現的AI 模型的推理成本從2022 年11 月的每百萬tokens 20 美元，降至2024 年 ...","doc_type":"web_page","link":"https://hk.finance.yahoo.com/news/%E5%8F%B2%E4%B8%B9%E4%BD%9B-2025%E5%B9%B4ai%E6%8C%87%E6%95%B8%E5%A0%B1%E5%91%8A-ai%E6%AD%A3%E4%BB%A5%E5%89%8D%E6%89%80%E6%9C%AA%E6%9C%89%E9%80%9F%E5%BA%A6%E9%87%8D%E5%A1%91%E4%B8%96%E7%95%8C-%E9%99%B8ai%E5%B0%88%E5%88%A9%E6%95%B8%E5%8D%A0%E5%85%A8%E7%90%83%E4%B8%83%E6%88%90-090005026.html","title":"史丹福報告：AI正以前所未有速度重塑世界 - Yahoo 財經"},{"content":"por 陈华 · 2024 · Mencionado por 1 — 摘要：最近，随着大数据和硬件能力的快速增长，人工智能取得了显著发展，人工神经网络. （Artificial Neural Network，ANN）已被成功应用于解决学术界和工业界的许多问题。","doc_type":"web_page","link":"http://gnclyqjxb.xml-journal.net/cn/article/pdf/preview/10.20027/j.gncq.2024.0042.pdf","title":"低功耗人工智能计算系统研究进展综述"},{"content":"... 推理速度上提升30 倍，显. 著降低了训练推理的成本和能耗。数据资源上，大规模、高质量、多. 类型的数据集蕴含着丰富的语义知识，有助于提高大模型的技术能力，. 充分释放 ...","doc_type":"web_page","link":"http://www.caict.ac.cn/kxyj/qwfb/ztbg/202409/P020240904538515747964.pdf","title":"大模型落地路线图研究报告 - 中国信息通信研究院"},{"content":"... 推理大语言模型性能比H100提升30倍，成本和能耗降至25分之一。 科技巨头对AI芯片的需求持续增长。例如，字节跳动的文本模型和视频模型推理算力需求巨大，预计其增量AI ...","doc_type":"web_page","link":"https://cs1.sdufe.edu.cn/info/1778/8025.htm","title":"2024年AI有哪些前沿进展？2025年又有哪些值得关注？"},{"content":"从能耗的角度来看，人类大脑只需要大约20瓦的功率即可维. 持运转，这约等于 ... 2024年8月12日，微软亚洲研究院新星科技节成功举办，此. 次活动汇聚了来自清华大学 ...","doc_type":"web_page","link":"https://www.microsoft.com/en-us/research/wp-content/uploads/2025/03/matrix70.pdf","title":"01 焦点02 前沿求索"},{"content":"预计未来五年全球算力规模将以超过50%的速度增. 长。数据中心的本质是把电力转换为算力。一方面，算力的激增带来能耗的激增，另一方面， ...","doc_type":"web_page","link":"https://digitalpower.huawei.com/attachments/index/dde142a639e64e3696392e190649d301.pdf","title":"2024年数据中心能源十大趋势- 白皮书"},{"content":"在此背景下，我院发布《人工智能发展报告（2024年）》，旨在. 总结梳理人工智能技术创新方向、产业升级重点、行业落地趋势和安. 全治理进展，展望人工智能发展 ...","doc_type":"web_page","link":"http://221.179.172.81/images/20241210/92391733821803495.pdf","title":"人工智能发展报告 - 通信世界"}],"7B以下 轻量级多模态模型 架构设计":[{"content":"本文将重点介绍一类参数量相对较小的多模态大模型，如1亿（1B）、2亿（2B）和7亿（7B）参数的模型。这些模型以其精巧的设计和优化的架构，在保持强大功能的同时，显著降低了对计算 ...","doc_type":"web_page","link":"https://zhuanlan.zhihu.com/p/703406724","title":"多模态小模型系列"},{"content":"Gemma 是最前沿的轻量级开放式模型系列，基于与打造Gemini 模型相同的研究和技术构建而成。 Gemma 的不同变体专为不同的用例和模态而设计，例如： ... 多模态 ...","doc_type":"web_page","link":"https://developers.googleblog.com/zh-hans/gemma-explained-overview-gemma-model-family-architectures/","title":"解析Gemma：Gemma 模型系列架构概述"},{"content":"本项目使用的具体版本是基于Mistral 7B 的大语言模型：llava-hf/llava-v1.6-mistral-7b-hf。Mistral 7B 是一个相对轻量级但性能优秀的语言模型，这使得我们 ...","doc_type":"web_page","link":"https://aws.amazon.com/cn/blogs/china/multimodal-large-model-application-practice-part-one/","title":"多模态大模型应用实践（一）- 利用微调LLaVA 实现高效酒店 ..."},{"content":"研究中，该团队首先从一个10 亿参数的小模型开始，逐步扩展到几十亿参数规模的模型，一步一步地走完了整个多模态预训练流程。 过程中他们从数据、模型架构与 ...","doc_type":"web_page","link":"https://www.mittrchina.com/news/detail/13194","title":"科学家打造多模态开源模型，7B和1.3B小模型均开源"},{"content":"InternLM2 包含两种模型规格：7B 和20B。7B 为轻量级的研究和应用提供了一个轻便但性能不俗的模型，20B 模型的综合性能更为强劲，可以 ...","doc_type":"web_page","link":"https://github.com/HqWu-HITCS/Awesome-Chinese-LLM","title":"HqWu-HITCS/Awesome-Chinese-LLM: 整理开源的 ..."},{"content":"这篇文章主要是对于磐石：多模态大模型系列多模态大模型综述: 数据、训练任务、架构分类的补充，侧重一些遗漏的网络结构和预训练过程两方面的内容 ...","doc_type":"web_page","link":"https://zhuanlan.zhihu.com/p/703468054","title":"多模态大模型系列多模态大模型综述: 数据、训练任务"},{"content":"本文提出了轻量化多模态大模型LLaVA-MoD，通过集成稀疏专家混合（MoE）架构来优化小模型的网络结构。 并设计了Dense-to-Sparse蒸馏框架，结合模仿蒸馏和偏好 ...","doc_type":"web_page","link":"https://blog.csdn.net/tMb8Z9Vdm66wH68VX1/article/details/147832335","title":"ICLR 2025 | LLaVA-MoD：MoE蒸馏训练轻量化多模态大模型"},{"content":"如图1(a)所示，LLaVA-1.5的架构包括三个关键组成部分：预训练的视觉编码器、预训练的LLM以及从零开始训练的中间多模态连接器。 对于输入图像，它被表示为LLM ...","doc_type":"web_page","link":"https://developer.volcengine.com/articles/7382344529577246770","title":"高效轻量级LLM | Imp模型，通过低比特量化分辨率和降低 ..."},{"content":"您需要高质量、可定制的模型选项，以便支持在数据中心、边缘计算和设备端用例等不同计算环境中托管和部署的大规模服务，例如使用GPU、DPU 和Jetson 等硬件 ...","doc_type":"web_page","link":"https://developer.nvidia.com/zh-cn/blog/lightweight-multimodal-multilingual-gemma-3-models-are-streamlined-for-performance/","title":"轻量级、多模态、多语种Gemma 3 模型实现性能优化"},{"content":"高效推理：Mini-InternVL 通过动态分辨率输入策略和像素洗牌操作，显著减少视觉标记数量，提升处理效率。 跨领域适应：基于知识蒸馏和转移学习技术，Mini- ...","doc_type":"web_page","link":"https://blog.csdn.net/qq_19841021/article/details/145216872","title":"Mini-InternVL：轻量级多模态大模型，4B 参数量媲美 ..."}],"视觉-语言融合机制 参数量 效率分析":[{"content":"最近，许多基准和数据集的开发旨在使用视觉问答（VQA）对来评估视觉-语言模型（VLM），并且模型已经显示出显著的准确性提升。然而，这些基准很少测试模型准确完成视觉蕴含的能力， ...","doc_type":"web_page","link":"https://github.com/chenin-wang/awesome_ai_paper","title":"chenin-wang/awesome_ai_paper"},{"content":"其中，Bunny-3B 取得了全新SOTA，性能全面碾压7B 以下模型，在多个基准上超越了Imp、LLaVA-Phi、MobileVLM 等一系列近期热门模型，取得了与LLaVA-v1.5-13B 等 ...","doc_type":"web_page","link":"https://hub.baai.ac.cn/view/35289","title":"Bunny-3B: 数据浓缩技术让3B多模态小模型媲美13B大模型"},{"content":"数据集分为两类：20个在分布数据集用于训练和在分布数据集用于评估，共有16个。作者报告了所有36 个任务的性能指标。MMEB 的概述如图2 所示，数据集统计信息 ...","doc_type":"web_page","link":"https://cloud.tencent.com/developer/article/2486052","title":"VLm2Vec：基于MMEB 训练，通用多模态嵌入模型的崛起！"}]}