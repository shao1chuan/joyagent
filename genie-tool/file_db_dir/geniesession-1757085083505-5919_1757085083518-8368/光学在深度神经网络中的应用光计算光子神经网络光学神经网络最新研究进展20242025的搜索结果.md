# 光学在深度神经网络中的应用：光计算与光子神经网络最新研究进展（2024-2025）

## 执行摘要

光学计算技术作为新型计算范式，在深度神经网络领域展现出革命性潜力。2024至2025年间，光子神经网络（PNN）与光学神经网络（ONN）研究取得显著突破，主要体现在**架构创新**、**规模扩展**、**能效提升**和**应用拓展**四个方面。根据中国信息通信研究院发布的《光计算技术与产业发展研究报告》，基于前馈神经网络的光计算研究主要集中在光学线性加权总和、光学线性卷积、光学非线性激活函数和光学系统上的在线网络训练四个核心方向[[1]](http://www.caict.ac.cn/kxyj/qwfb/ztbg/202311/P020231122389415230856.pdf)。清华大学、麻省理工学院、宾夕法尼亚大学等机构在光子处理器设计、全光神经网络训练和大规模集成芯片方面实现了重大技术突破，将光学神经网络规模提升至百万神经元级别，能效达到每秒每瓦160万亿次运算(160 TOPS/W)[[38]](http://henan.kjzch.com/luoyang/2024-04-15/841815.html)。这些进展为人工智能计算提供了超低延时、超低能耗的全新解决方案，有望彻底改变传统电子计算架构的性能瓶颈。

## 第一章 光子神经网络的技术原理与基础架构

### 1.1 光子神经网络的基本概念与定义

光子神经网络（Photonic Neural Networks, PNN）是一种利用光学器件及相关物理效应，在光域中直接实现神经网络关键数学运算的新型计算架构。根据北京大学王兴军教授课题组的定义，PNN的核心理念在于利用特定的光学器件及相关物理效应，在光域中直接实现神经网络所涉及的关键数学运算，如向量矩阵乘法、卷积操作以及非线性激活函数等[[32]](https://www.opticsjournal.net/Articles/OJ4b4a30bfeac814d7/FullText)。这种计算模式区别于传统的电子计算，利用光子作为信息载体，通过光学干涉、衍射、调制等物理过程实现计算功能。

中国信通院梁林俊等研究人员指出，光计算技术是光子技术与计算技术深度交叉融合形成的新型计算技术。基于光学神经网络的光计算技术和基于量子光学的光计算技术是受关注度较高、产业化应用前景较好的两大类技术路线[[9]](https://www.gdec.net.cn/actives/newsdetail?id=336)。这两种技术路线虽然物理基础不同，但都致力于利用光子的独特属性提升计算效率。

### 1.2 光子神经网络的关键技术组件

光子神经网络的实现依赖于多个关键技术组件的协同工作，主要包括光学线性运算单元、非线性激活函数和训练机制三大核心部分。

**光学线性运算单元**负责实现神经网络中的线性变换操作。基于前馈神经网络的光计算研究主要集中在以下四个方面：光学线性加权总和、光学线性卷积、光学非线性激活函数和光学系统上的在线网络训练[[1]](http://www.caict.ac.cn/kxyj/qwfb/ztbg/202311/P020231122389415230856.pdf)。其中，光学线性加权总和通过光干涉和衍射效应实现，光学线性卷积则利用光学傅里叶变换特性完成。

**非线性激活函数**是神经网络实现复杂映射能力的关键。传统光学系统缺乏天然的非线性响应，这是光学神经网络长期面临的挑战。2025年，研究人员取得了重要突破，基于锗材料低损耗的非线性激活特性，成功制造了三级隐藏层级联光学神经网络。该芯片支持最多64路输入和10路输出，占地面积仅为2.04mm²，实现了全光非线性运算[[13]](https://clp.ac.cn/M/News/Details?id=PT250523000111eBhEj)。

**训练机制**方面，光学神经网络面临独特挑战。2024年，中山大学研究团队开发的新型光学神经网络芯片，使快速训练成为可能[[17]](https://seit.sysu.edu.cn/research/progress)。该芯片采用原位训练算法，避免了传统训练方法中的大量数据传输，显著提升了训练效率。

### 1.3 光子神经网络的物理实现架构

光子神经网络的物理实现主要分为片上集成和自由空间两种架构，各有其技术特点和适用场景。

**片上集成架构**将光学元件集成在芯片上，实现紧凑型光学计算系统。清华大学方璐团队在2024年首创分布式广度光计算架构，研制出全球首款大规模干涉-衍射异构集成芯片——太极[[10]](https://www.oejournal.org/oee/article/doi/10.12086/oee.2024.240101)。这种架构通过干涉和衍射的有机结合，实现了高效率的光学计算。

**自由空间架构**利用光学元件在自由空间中的传播特性实现计算功能。上海理工大学顾敏院士和张启明教授团队的研究实现了重要的范式突破——利用光传播的物理特性构建了光学神经元之间的连接网络，首次在光学系统中完整实现了神经网络功能[[22]](https://mittrchina.com/news/detail/14785)。这种架构适用于大规模并行计算任务。

两种架构各有优势：片上集成系统具有体积小、稳定性高的优点，适合嵌入式应用；自由空间系统则具有并行度高、可扩展性强的特点，适合大规模数据处理任务。项水英2025年的研究系统地梳理了这两种光子神经网络架构的优劣势[[31]](https://www.oejournal.org/oee/article/doi/10.12086/oee.2024.240101)。

## 第二章 2024-2025年光学神经网络关键技术突破

### 2.1 大规模集成与架构创新

2024年至2025年，光学神经网络在大规模集成和架构创新方面取得了显著进展，多项研究成果突破了传统光计算的技术瓶颈。

清华大学电子系方璐团队在大规模光电智能计算方向取得重要进展。其开发的DANTE系统突破了大规模光电神经网络物理建模复杂、参数优化困难等桎梏，网络规模提升一至两个数量级，训练学习速度提升两个数量级[[29]](https://www.tsinghua.edu.cn/info/1175/107842.htm)。该系统采用光学-人工双神经元学习框架，有效解决了大规模光学神经网络训练难题。

我国研究人员探索出光子芯片新架构，将光神经网络规模提高到百万神经元级别。该架构可有效地将光神经网络的规模提高到百万神经元级别，将能源效率提高到每秒每瓦(TOPS/W)执行运算160万亿次。该成果实现了单片上1396万个神经元的光神经网络，创造了当时的世界纪录[[38]](http://henan.kjzch.com/luoyang/2024-04-15/841815.html)。

在超大型光学神经网络架构方面，研究人员提出了一种简洁的光学神经网络芯片框架结构，实现了一整层的神经网络，计算速度达到120 GOPS，同时输入和输出的数量能够被灵活调整以应对多种AI任务[[24]](https://news.sciencenet.cn/sbhtmlnews/2024/11/382210.shtm)。这种架构设计为光学神经网络的实际应用奠定了基础。

### 2.2 非线性光学功能突破

非线性计算功能一直是光学神经网络的难点，2024-2025年间，多项研究在这一领域取得了突破性进展。

美国宾夕法尼亚大学的工程师开发出了一款能够利用光进行非线性神经网络训练的可编程芯片。这不仅有望显著加快AI训练速度，还能大幅降低能耗[[20]](https://www.sohu.com/a/886987373_122256621)。该芯片采用创新的光学非线性单元设计，实现了与传统电子神经网络相当的性能。

麻省理工学院研究人员提出创新的非线性单元设计来实现相干光子神经网络架构。该架构由多个层和相互连接的神经元构成，数据在这些神经元与层之间以光的形式传输和处理，实现了超低延时和超低能耗[[35]](https://clp.ac.cn/M/News/Details?id=PT2412220001283Z6c9)。

上海理工大学研究团队利用物理变换打破了用物理过程模拟数字计算不可避免的误差问题。他们利用不依赖数学表达的物理变换赋能光子神经网络，充分发挥光学的内在优势提升任务精度，实现了99%以上的任务精度[[23]](https://m.opticsjournal.net/J/NewOptics/news/PT250719000006TzW3Z.html)。

### 2.3 训练算法与编程模型

光学神经网络的训练算法和编程模型在2024-2025年间取得了重要进展，解决了光计算系统与传统神经网络训练框架的兼容性问题。

中山大学研究团队开发的新型光学神经网络芯片，使快速训练成为可能。该芯片采用秒级别完成高维度数据的处理，实现了原位模型训练，显著提升了AI系统性能[[33]](https://seit.sysu.edu.cn/sites/default/files/2024-11/%E7%A7%91%E7%A0%94%E5%8A%A8%E6%80%81-%E6%96%B0%E5%9E%8B%E5%85%89%E5%AD%A6%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E8%8A%AF%E7%89%87%EF%BC%8C%E4%BD%BF%E5%BF%AB%E9%80%9F%E8%AE%AD%E7%BB%83%E6%88%90%E4%B8%BA%E5%8F%AF%E8%83%BD.pdf)。

2024年，Cheng等研究人员拓展了波长多路复用策略，将不同任务的数据样本加载在不同的光学波长下，并采用持续学习的思想，利用1个光计算实验系统完成了5个不同任务的处理[[15]](https://www.opticsjournal.net/Articles/OJ96a4e58e5a61f917/FullText)。这种方法大大提高了光学计算系统的灵活性和利用率。

可编程光子芯片首次实现了用光训练神经网络。在一项研究中，这种新型芯片在MNIST数据集问题上达到了96%以上的准确率。这表明，与传统数字神经网络相比，光子芯片不仅性能相当，甚至更优，而且能耗更低[[34]](http://www.hfnl.ustc.edu.cn/detail?id=22948)。

## 第三章 光学神经网络的应用场景与性能表现

### 3.1 图像识别与计算机视觉

光学神经网络在图像识别和计算机视觉领域展现出卓越性能，其并行处理能力和高速计算特性特别适合这类应用。

卷积光学神经网络开启了人工智能成像新时代。上海理工大学的研究团队开发了一项关键技术，构建了一个多阶段的卷积网络，它由多个并行核心组成，能够以光速进行操作，直接从散射光中提取特征，实现图像的快速重建。这一过程不仅极大提高了成像速度，还保持了高精度[[14]](https://www.usst.edu.cn/2024/0614/c929a58577/page.htm)。

香港科技大学的科研人员成功研发全球首个可用作深度机器学习的全光学神经网络，能够让人工智能在处理较复杂的问题上，例如辨识事物之间的关系，表现更为高效。这项技术在图像识别和复杂视觉任务中表现出色[[28]](https://science.hkust.edu.hk/zh-hans/node/7397)。

光子处理器在AI计算中的技术创新包括非线性光学功能单元（NOFUs）的引入，在图像识别等深度学习任务中表现出卓越性能[[3]](https://www.forwardpathway.com/147891)。这些光学处理器的并行计算能力使其特别适合处理大规模图像数据。

### 3.2 自然语言处理与语音识别

光学神经网络在自然语言处理和语音识别领域也显示出巨大潜力，其高速处理能力可以显著提升这些应用的性能。

光子处理器在自然语言处理任务中表现出卓越性能[[3]](https://www.forwardpathway.com/147891)。光学计算的高并行性特别适合处理语言模型中的大量矩阵运算，可以显著加速推理过程。

基于光衍射的计算系统把光学传播转化为矩阵变换，实现了人工智能在物理层的加速。利用光学衍射的传播规律，可并行完成卷积、矩阵向量乘法等计算任务，这些操作在自然语言处理中广泛应用[[27]](https://clp.ac.cn/M/News/Details?id=PT2506060000847dAgD)。

神经网络算法在数字经济中的实际案例研究表明，许多企业通过应用神经网络算法有效提升了运营效率与管理水平。这些成功案例不仅体现了该技术在促进企业转型升级中的积极作用，也展示了其在复杂数据处理任务中的优势[[6]](https://blog.csdn.net/tiangang2024/article/details/144422847)。

### 3.3 科学计算与特殊应用

光学神经网络在科学计算和特殊应用领域展现出独特优势，特别是在需要实时处理和高能效的场景中。

在光通信领域，与人工智能驱动的深度学习算法结合，显著提升了传输性能。在光学信号监测中，人工智能利用大数据分析和深度学习，从广泛的监控数据中提取有价值的信息[[18]](https://clp.ac.cn/M/News/Details?id=PT2506060000847dAgD)。

深圳大学物理与光电工程学院张晗教授团队研发的光致荧光神经网络运算功能，构建出全新的"感知–记忆–计算–显示"一体化光计算硬件平台，为未来的可穿戴设备、边缘AI感知系统提供了新的解决方案[[25]](https://www.szu.edu.cn/info/1302/20342.htm)。

科学家研制的50万维向量光学设备，架构矩阵或向量维度可做到将近50万。在此情况下，每个乘法运算只需要小于一个光子就能进行，这个能量效率远超传统电子计算设备[[39]](https://www.mittrchina.com/news/detail/10221)。

## 第四章 技术挑战与发展趋势

### 4.1 当前面临的技术挑战

尽管光学神经网络取得了显著进展，但仍然面临多项技术挑战，需要进一步研究和突破。

**统一架构缺失**是目前光学神经网络发展的主要障碍之一。根据CNCC技术论坛的分析，神经网络架构的光计算有望用于空间信号、时间信号以及片上信息的处理。但目前，光神经网络计算还欠缺统一架构，面向不同的应用需求，所采用的物理结构各不相同[[5]](https://www.ccf.org.cn/Focus/2024-09-23/830213.shtml)。

**系统集成挑战**是另一个重要问题。探索具有高性能的光电混合计算硬件系统或全光计算硬件系统的架构创新上，两者需并驾齐驱[[36]](https://www.researchgate.net/profile/Bei-Chen-27/publication/364253602_guangxueshenjingwangluojiqiyingyongfengmianwenzhang/links/658a2efd2468df72d3d82f52/guangxueshenjingwangluojiqiyingyongfengmianwenzhang.pdf)。如何将光学计算元件与电子控制单元高效集成，是实际应用中的关键挑战。

**精度和误差问题**也是光学神经网络需要解决的重要课题。虽然物理变换方法在一定程度上突破了精度限制，实现了99%以上的任务精度[[23]](https://m.opticsjournal.net/J/NewOptics/news/PT250719000006TzW3Z.html)，但在更复杂的任务中，如何保持高精度仍然是需要持续研究的问题。

### 4.2 产业化与应用前景

光学神经网络的产业化前景广阔，但全面落地仍需时间和技术积累。

**产业化应用前景**方面，基于光学神经网络的光计算技术和基于量子光学的光计算技术是受关注度较高、产业化应用前景较好的两大类技术路线[[9]](https://www.gdec.net.cn/actives/newsdetail?id=336)。这两类技术各有特点，适用于不同的应用场景。

**商业化突破**已经初步显现，但落地仍需时间。一方面，光计算芯片将成为人工智能计算的重要硬件支撑，提升深度学习模型的训练和推理速度；另一方面，人工智能算法也将助力光计算系统的优化，实现更高效的计算[[8]](https://www.eet-china.com/mp/a395968.html)。

**企业应用案例**逐渐增多。实际案例研究表明，许多企业通过应用神经网络算法有效提升了运营效率与管理水平。这些成功案例不仅体现了该技术在促进企业转型升级中的积极作用，也展示了其应用潜力[[6]](https://blog.csdn.net/tiangang2024/article/details/144422847)。

### 4.3 未来发展趋势与研究方向

光学神经网络的未来发展趋势主要体现在架构创新、材料突破和应用拓展三个方向。

**架构创新**将继续深入。智能光子学研究中，系统性地梳理了实现动态光子结构的创新材料体系与器件架构，涵盖从超构表面到集成光子芯片等多个维度，重点剖析智能光子学中实现可重构性的技术路径[[37]](https://www.iikx.com/news/progress/33360.html)。

**材料体系创新**将推动性能提升。基于锗材料低损耗的非线性激活特性，研究人员成功制造了多级隐藏层级联光学神经网络，为全光非线性计算提供了新的材料解决方案[[13]](https://clp.ac.cn/M/News/Details?id=PT250523000111eBhEj)。

**应用领域拓展**将持续进行。光学神经网络有望用于空间信号、时间信号以及片上信息的处理[[5]](https://www.ccf.org.cn/Focus/2024-09-23/830213.shtml)。随着技术成熟，其应用领域将从目前的图像识别、自然语言处理扩展到更多需要高速计算的领域。

## 第五章 学术研究与国际合作

### 5.1 重要研究机构与团队

光学神经网络研究在全球范围内广泛开展，多个研究团队在这一领域做出了重要贡献。

**中国研究团队**取得了显著成果。清华大学方璐团队首创分布式广度光计算架构，研制出全球首款大规模干涉-衍射异构集成芯片——太极[[10]](https://www.oejournal.org/oee/article/doi/10.12086/oee.2024.240101)。上海理工大学顾敏院士团队开发光学AI芯片，将光纤传输能力提升1万倍[[22]](https://mittrchina.com/news/detail/14785)。中山大学蔡鑫伦教授团队研究成果成功入选"2022中国光学十大进展"[[17]](https://seit.sysu.edu.cn/research/progress)。

**国际研究团队**也取得了重要突破。麻省理工学院的Shen Yichen博士等人进行了一项开创性的研究，提出了一条既能降低延迟又能提高能源效率的途径：光神经网络(ONNs)[[7]](https://www.infoq.cn/article/szyxsfuh5q4vtbu_vvy2)。美国宾夕法尼亚大学的工程师开发出了能够利用光进行非线性神经网络训练的可编程芯片[[20]](https://www.sohu.com/a/886987373_122256621)。

**学术交流活动**促进了研究进展。2025年5月，智能科技学院在光电大楼成功举办"国际光日"系列活动——"光熠思辨"学术分享会暨"光启未来"光学知识科普与竞答活动[[26]](https://saist.usst.edu.cn/2025/0517/c16113a341489/page.htm)。这类活动促进了学术交流和知识传播。

### 5.2 重要学术成果与论文发表

2024-2025年间，光学神经网络领域产生了大量重要学术成果和高水平论文。

**综述论文**系统总结了领域进展。《光子神经网络关键技术与进展》特约综述系统性地梳理和