{"轻量级神经网络结构 MCU-Net ProtoNN 对比综述 2022-2025":[],"模型压缩 SOTA 方法 量化 剪枝 性能对比 边缘计算":[{"content":"... 量化是模型的“压缩模式”。 具体方法：. 训练后量化 ... 微调（Fine-tune）：重新训练剪枝后的模型，恢复性能。 迭代剪枝：重复上述过程，逐步压缩模型。","doc_type":"web_page","link":"https://zhuanlan.zhihu.com/p/21546819636","title":"一文读懂AI模型量化、蒸馏和剪枝"},{"content":"非结构化剪枝能极大降低模型的参数量和理论计算量，但是现有硬件架构的计算方式无法对其进行加速，所以在实际运行速度上得不到提升，需要设计特定的硬件才 ...","doc_type":"web_page","link":"https://blog.csdn.net/Xiao_Ya__/article/details/139326851","title":"知识蒸馏_模型剪枝和量化"},{"content":"本研究通过评估四种主要的模型压缩技术：量化、低秩近似、知识蒸馏和剪枝，来解决这一挑战。系统地分析和比较了这些技术及其组合在优化ViT以适应资源受限 ...","doc_type":"web_page","link":"https://www.cvmart.net/community/detail/8632","title":"一文详解视觉Transformer模型压缩和加速策略(量化/低秩 ..."},{"content":"我们展示了真实世界数据集的深度神经网络的实验结果，并将我们提出的算法的性能与之前文献中提出的压缩SGD 方法进行了比较，并展示了CIFAR-100 和CIFAR-10 ...","doc_type":"web_page","link":"https://zhuanlan.zhihu.com/p/545864525","title":"Efficient AI & 边缘AI & 模型轻量化技术文章推荐（07.25）"},{"content":"在边缘计算的模型压缩中，优化压缩率有助于提升边缘设备的性能和效率，同时减少计算资源的消耗。例如，模型剪枝可以通过移除不必要的神经元或连接减少模型 ...","doc_type":"web_page","link":"https://blog.csdn.net/layneyao/article/details/147640727","title":"AI模型压缩与优化：如何在资源受限设备上运行大模型？"},{"content":"... 模型大小并加速模型训练/推断，同时不会显着降低模型性能。 模型压缩技术可以分为两类：剪枝和量化。 剪枝方法探索模型权重中的冗余， 并尝试删除/修剪冗余和非关键的权重。","doc_type":"web_page","link":"https://nni.readthedocs.io/zh/v2.7/compression/overview.html","title":"模型压缩"},{"content":"上述模型压缩方法能配合使用，一个模型经过结构化剪枝之后，由于其结构没有发. 生重要变化，所以能紧接着进行低秩近似以减少参数量和计算量，最后再通过参数量化. 进一步减少 ...","doc_type":"web_page","link":"https://cs.nju.edu.cn/wujx/paper/Pruning_Survey_MLA21.pdf","title":"第1 章结构化剪枝综述"},{"content":"模型压缩架构和流程介绍！量化/剪枝/蒸馏/二值化4件套！【推理系统】模型压缩第01篇. ZOMI酱. 相关推荐. 查看更多. 知识蒸馏SOTA算法解读！【推理引擎】模型压缩系列第06篇.","doc_type":"web_page","link":"https://www.bilibili.com/video/BV1384y187tL/","title":"模型压缩架构和流程介绍！量化/剪枝/蒸馏/二值化4件套！【 ..."},{"content":"by 宁欣 · 2024 · Cited by 1 — 较低的剪枝率可能压缩比达不到部署的 要求；较高的剪枝率可能导致模型精度的严重 下降。 量化是指降低网络参数的位宽来压缩模型和 高效计算。 可量化的网络参数包括权重、 ...","doc_type":"web_page","link":"http://tis.hrbeu.edu.cn/Upload/PaperUpLoad/c47a05a1-6a97-431f-9264-eb2c6f3c998f.pdf","title":"神经网络压缩联合优化方法的研究综述"},{"content":"结合pruning，quantization和huffman encoding等多种方法，将网络size压缩了几十倍，性能获得成倍的提升。其中对于pruning带来的精度损失，使用了iterative ...","doc_type":"web_page","link":"https://www.cnblogs.com/wujianming-110117/p/12702802.html","title":"深度学习网络模型压缩剪枝详细分析- 吴建明wujianming"}],"TinyML 硬件部署 能耗 延迟 指标优化 MCU 2023-2025":[],"物联网数据集 SpeechCommands VisualWakeWords 规模 评测协议 基准测试":[{"content":"作为全球公认的人工智能领域权威资源之一，人工智能指数报告被《纽约时报》、彭博社和《卫报》等主要媒体引用，成为. 数百篇学术论文的文献参考，并服务于 ...","doc_type":"web_page","link":"https://hai.stanford.edu/assets/files/hai_ai_index_report_2025_chinese_version_061325.pdf","title":"介绍2025年人工智能指数报告 - Stanford HAI"},{"content":"我们通过两项关键创新来实现这一目标：1) 消除对末端执行器位置预测的自回归要求，从而使推理速度提高7倍；2) 利用小型语言模型（SLMs）的效率，在显著降低计算需求的情况下，展示 ...","doc_type":"web_page","link":"https://github.com/chenin-wang/awesome_ai_paper","title":"chenin-wang/awesome_ai_paper"},{"content":"AllenAct 是由Allen Institute for AI（AI2）推出的模块化具身智能训练框架，专为视觉导航、目标探索、语义问答等复杂交互任务设计，具备高度的策略结构灵活性 ...","doc_type":"web_page","link":"https://blog.csdn.net/sinat_28461591/article/details/147990336","title":"【GitHub开源项目实战】AllenAct 实战全解析：模块化具身智能 ..."},{"content":"动态调整是克服固定超参数局限性 ... 模型族和资源： 发布了RM-R1系列模型（7B到32B）、训练代码和数据，极大地促进了可复现研究和社区在此方向上的进一步探索。","doc_type":"web_page","link":"https://zhuanlan.zhihu.com/p/1905142904579659503","title":"爱可可AI 前沿推介(5.12)"},{"content":"与在传统机器学习领域进行的对抗性攻击不同，. 面向大语言模型的越狱攻击不涉及对图像的处理或. 优化，也不需要大量关于大语言模型的专业知识. 在. 大部分场景下，一个不具备 ...","doc_type":"web_page","link":"https://crad.ict.ac.cn/cn/article/pdf/preview/10.7544/issn1000-1239.202330962.pdf","title":"面向大语言模型的越狱攻击综述"},{"content":"组件多样性： 应用程序的复杂度各异，从简单的API 接口到复杂的前端应用，甚至能整合上下文信息（通过持久层、语义索引或插件实现）。 功能扩展性： 高级的AI 应用程序可与现 ...","doc_type":"web_page","link":"https://github.com/Acmesec/theAIMythbook","title":"Ai迷思录（应用与安全指南）"},{"content":"深度学习框架作为连接应用场景和硬件平台的中间部件, 向上支撑深度学习应用的开发, 帮助用户快速构造不同的深度神经网络模型, 向下深度适配各类计算硬件, 满足不同算力架构 ...","doc_type":"web_page","link":"https://www.jos.org.cn/html/2024/8/7059.htm","title":"深度学习框架测试研究综述"},{"content":"在开源方案中，深度势能团队开发维护的Uni-Fold. 是首款完全开源且成功复现大规模训练的工具，不. 仅成功复现了AlphaFold2 的全规模训练，并且克. 服了 ...","doc_type":"web_page","link":"https://image.deeptechchina.com/2023%E7%89%88%E3%80%8A%E7%A7%91%E5%AD%A6%E6%99%BA%E8%83%BD%28AI4S%29%E5%85%A8%E7%90%83%E5%8F%91%E5%B1%95%E8%A7%82%E5%AF%9F%E4%B8%8E%E5%B1%95%E6%9C%9B%E3%80%8B.pdf","title":"科学智能(AI4S) 全球发展观察与展望 - DeepTech"},{"content":"回顾OpenAI 的早. 期论文，实际上早在GPT-2 的论文中，就深入讨论了基于大规模文本预训练的通. 用任务学习范式，让人不禁感叹OpenAI 团队的技术前瞻性。虽然 ...","doc_type":"web_page","link":"https://llmbook-zh.github.io/LLMBook.pdf","title":"LLMBook.pdf - 大语言模型"},{"content":"什么是生成式人工智能及如何运行生成式人工智能教育与研究应用指南6．对生成的响应进行后处理，以提高其可读性和自然性。这一过程可能包括应用格式、标点以及其他增强性 ...","doc_type":"web_page","link":"https://unesdoc.unesco.org/ark:/48223/pf0000393559","title":"生成式人工智能教育与研究应用指南"}],"嵌入式AI 可复现性 超参数 预处理代码 开源实现 权威综述":[{"content":"为了解决这个问题，开发人员创建了可以用小型电池（例如CR2032 纽扣电池）供电的专用低功耗硬件。 ... 针对架构延迟的优化，还可以使用基于硬件的概要（hardware- ...","doc_type":"web_page","link":"https://www.infoq.cn/article/ihfwg4lc9gem349nsek7","title":"TinyML：下一轮人工智能革命_AI&大模型"},{"content":"TinyML指的是为在资源受限的设备上部署人工智能而优化的机器学习模型和技术。这些设备在边缘运行，在那里生成数据，并在本地执行推理。TinyML系统通常在低功 ...","doc_type":"web_page","link":"https://www.eet-china.com/newsexpress/73746.html","title":"MCU AI/ML - 弥合智能和嵌入式系统之间的差距"},{"content":"TinyML对于直接在设备上实现智能决策、促进实时处理和减少延迟至关重要，特别是在连接有限或无连接的环境中。 TinyML是指在小型、低功耗设备上应用机器学习 ...","doc_type":"web_page","link":"https://www.52solution.com/news/80058969/","title":"低功耗MCU上的人工智能与机器学习实现策略"},{"content":"What：TinyML是指超低功耗（毫瓦量级）的边缘侧机器学习应用。 · Why：TinyML可以提升大量物联网设备的数据分析和决策能力。 · How：TinyML的实现需要硬件、软件 ...","doc_type":"web_page","link":"https://www.eet-china.com/mp/a44166.html","title":"在边缘侧实现超低功耗机器学习【物女心经】"},{"content":"测试结果的好坏指标包含得到推论结果所需要的时间愈快愈好(延迟，单位：毫秒)、推论结果愈精准愈好(精确度，单位：百分比)、耗用的电能愈低愈好(单位：微焦耳) ...","doc_type":"web_page","link":"https://www.elecfans.com/emb/danpianji/202209201895872.html","title":"利用TinyML在MCU上实现AI/ML推论工作"}]}